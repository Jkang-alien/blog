[{"authors":["admin"],"categories":null,"content":"Jun Kang is a clinical assistant professor of hospital pathology at the Catholic university of Korea. His research interests include pathology, oncology and statistics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Jun Kang is a clinical assistant professor of hospital pathology at the Catholic university of Korea. His research interests include pathology, oncology and statistics.","tags":null,"title":"Jun Kang","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":["Math"],"content":" It is the main subject of analysis that finding conditions making sequential mathematical objects like a set, sequence, series to be convergent. Induction changes \\(S = \\mathbb{N}\\) to \\(s_{1} \\in S\\) and if $ s_{n} S$ then \\(s_{n+1} \\in S\\). The natural number has a property of endless addable with one. But, induction can prove only natural number \\(\\mathbb {N}\\) not infinity \\(\\infty\\).\n\\[ Induction \\\\ s_{1} \\in S \\\\ if\\ s_{n} \\in S \\ then \\ s_{n+1} \\in S \\\\ Then\\ S = \\mathbb{N} \\\\ \\] The limit is the way \\(\\mathbb {N}\\) goes to \\(\\infty\\). But the limit operation should be justified by an axiom or a proof. \\(\\bigcup^{\\infty}_{n=1} U\\) is open, where \\(U\\) is open in topology. In the extended non-negative real line, an infinite series \\(\\Sigma_{n=1}^{\\infty} x_{n} \\in [0, \\infty]\\) is always convergent as a limit of the partial sum \\(\\Sigma_{n=1}^{N} x_{n}\\). In the sequence version, a sequence (\\(a_{n}\\)) is converges to real number if there exist \\(N \\in \\mathbb {N}\\) such that for every \\(n \\ge N\\), \\(\\lvert a_{n} - a \\rvert \u0026lt; \\epsilon\\) for every \\(\\epsilon \u0026gt; 0\\). This is the point where natural number \\(\\mathbb N\\) applies it’s property of endless addable with one. The \\(\\epsilon\\) can be replaced by neiborhood in topological space.\nThe series of \\(a_{n}\\) can be a series or just a set of a complex number \\(c \\in \\mathbb {C}\\), function, set, integration, differentiation, or other mathematical objects. But computing the limit is different by how the sequence or the set is processed. If the sequence is processed by union of sets, the limit is defined by computing element-wise limit \\(\\bigcap^\\infty_{n=1} A_n = \\{x|x \\in A_n \\ for \\ all \\ n \\in \\mathbb{N} \\}\\). Induction can not apply to the limit \\(\\bigcap_{n=1}^N A_n = \\{x|x \\in A_n \\ for \\ all \\ n \\in N\\}\\). The integration is defined by supremum of a set of simple function integral \\(Simp\\ \\int_{R^d} f(x) dx := c_1 m(E_1) + ... + c_k (E_k)\\). The Jordan measure is an infimum of the finite sum of element measure. The Lebesgue measure is an infimum of the infinite sum of element measure.\nIs the Lebesgue outer measure (\\(E^{*}\\ = \\ \\inf \\Sigma_{n=1}^{\\infty} m(E_n)\\) where \\(m(E)\\) is elementary measure and \\(A \\subset \\bigcup E_n\\)), a limit of Jordan measure (\\(\\lim\\sup \\Sigma_{n=1}^{N} m(E_n)\\))?\nMeasure can be considered as a optimizaion problem.\n\\[ minimize \\ \\Sigma_{n=1}^{\\infty} m(E_n) \\\\ suject \\ to \\ A \\subset \\bigcup E_n \\\\ where \\ m(E) \\ is \\ elementary \\ measure, \\ E \\ is \\ a \\ elementary \\ set \\]\nThe objective function \\(\\Sigma_{n=1}^{\\infty} m(E_n)\\) has infinite domain \\(f: E^{\\infty} \\to R\\) in Lebesgue outer measure and finite domain \\(f:E^{N} \\to R\\) in Jordan outer measure. The Lebesgue outer measure and Jordan outer measure has different domain space, then the objective function of the Lebesgue outer measure is not a limit of Jordan outer measure.\nOptimization problem has solution (\\(\\{E:E_n \\ , n \\in \\mathbb{N} \\ or \\ \\infty \\}\\)) at the saddle point where meets the objective function and the constraint. \\(A\\) that we measure is a parameter of the constraints. Measure is find solution (\\(\\{E:E_n \\ , n \\in \\mathbb{N} \\ or \\ \\infty \\}\\)) with constraints with \\(A\\) what we measure. Then the solution can be computed by approximation or limit process.\n","date":1609200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609195196,"objectID":"4c6149086f50d036126aebc1d945913c","permalink":"/post/2020-12-29-extended-non-negative-real-line-and-limit/","publishdate":"2020-12-29T00:00:00Z","relpermalink":"/post/2020-12-29-extended-non-negative-real-line-and-limit/","section":"post","summary":"It is the main subject of analysis that finding conditions making sequential mathematical objects like a set, sequence, series to be convergent. Induction changes \\(S = \\mathbb{N}\\) to \\(s_{1} \\in S\\) and if $ s_{n} S$ then \\(s_{n+1} \\in S\\). The natural number has a property of endless addable with one. But, induction can prove only natural number \\(\\mathbb {N}\\) not infinity \\(\\infty\\).\n\\[ Induction \\\\ s_{1} \\in S \\\\ if\\ s_{n} \\in S \\ then \\ s_{n+1} \\in S \\\\ Then\\ S = \\mathbb{N} \\\\ \\] The limit is the way \\(\\mathbb {N}\\) goes to \\(\\infty\\).","tags":["Analysis","Limit"],"title":"Convergence","type":"post"},{"authors":[],"categories":["Math","Machine learning"],"content":"  The Fourier series represents a periodic function as a descrete vectors. The Fourier transformation turns a time domain non-periodic function into a frequency domain continuous function. The Fourier series and transformation change a single time base \\(t\\) into infinite frequency basis \\(e^{inx}\\) or \\(e^{iwx}\\). The function on infinite basis domain can be represented by a vector or a function of basis domain \\(v_{n}\\) or \\(f(w)\\). This is a coefficients of Fourier series or Fourier transformation.\nThe basis of Fourier transformation is pure frequency \\(e^{iw}\\). The domain of Laplace transfomation is frequency \\(w\\) and damping component \\(\\sigma\\) which compose damping ocilation function, \\(e^{s} = e^{(iw+\\sigma)}\\). The function which represent Laplace transformation \\(F(s)\\) is a function of complex domain \\(s\\). The Fourier transformation is a special Laplace transformation of no damping term \\(s = 0 \\cdot \\sigma +iw\\).\nThe periodic function can be represented by a series not a continuous function. A condition makes a function can be represented by pure frequency domain i.e. Fourier transformation, not a complex domain i.e. Laplace transformation. The condition is\n from wikipedia https://en.wikipedia.org/wiki/Laplace_transform#Fourier_transform\n \\[\\begin{align} \\widehat{f}(\\omega) \u0026amp;= \\mathcal{F}\\{f(t)\\} \\\\[4pt] \u0026amp;= \\mathcal{L}\\{f(t)\\}|_{s = i\\omega} = F(s)|_{s = i \\omega} \\\\[4pt] \u0026amp;= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~. \\end{align}\\]\nLaplace transformation makes a differential equation to an algebra equation.\n\\[Laplace transformation\\]\n\\[ \\mathcal{L}[f(t)] = F(s) = \\int_{t=0}^{\\infty} f(t)e^{-st}dt \\]\n\\[Transfer function\\]\n\\[ H(s) = Y(s)/X(s) \\] \\[ Y(s) = H(s)X(s) \\]\nwhere \\(Y(s)\\) and \\(X(s)\\) are Laplace transformed \\(y(t)\\), i.e. solution and \\(f(t)\\) i.e. input.\nThe \\(Y(s)\\) is a function of \\(s\\) which represents coefficients of damped frquency basis \\(e^{\\sigma + iw}\\). We are not looking for the solution \\(s\\) for the \\(Y(s)\\). We are looking for the inverse Laplace transformation of \\(Y(s)\\). The inverse Laplace transformation turns a function \\(Y(s)\\) with infinite damped frquency basis \\(e^{\\sigma + iw}\\) to the solution of linear differential equation \\(y(t)\\) that is a function with a single domain basis \\(t\\).\nThe Laplace transformation has poles that blow up at a point. The poles were determined by constants of differential equation and the input term.\n","date":1605312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605313427,"objectID":"93ba6fcca78d34b89913ae3c692ac782","permalink":"/post/laplace-transformation/","publishdate":"2020-11-14T00:00:00Z","relpermalink":"/post/laplace-transformation/","section":"post","summary":"The Fourier series represents a periodic function as a descrete vectors. The Fourier transformation turns a time domain non-periodic function into a frequency domain continuous function. The Fourier series and transformation change a single time base \\(t\\) into infinite frequency basis \\(e^{inx}\\) or \\(e^{iwx}\\). The function on infinite basis domain can be represented by a vector or a function of basis domain \\(v_{n}\\) or \\(f(w)\\). This is a coefficients of Fourier series or Fourier transformation.","tags":["Deep Learning","Gilbert Strang","Machine learning","Math","Linear algebra"],"title":"Laplace transformation","type":"post"},{"authors":["Jun Kang","Ahwon Lee","Youn Soo Lee"],"categories":null,"content":"","date":1604880000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604880000,"objectID":"3a13bf1f478227faf1e8ea09bdef735d","permalink":"/publication/2020-11-09_kangpredictionpik3camutations2020/","publishdate":"2020-11-09T00:00:00Z","relpermalink":"/publication/2020-11-09_kangpredictionpik3camutations2020/","section":"publication","summary":"Breast cancers with PIK3CA mutations can be treated with PIK3CA inhibitors in hormone receptor-positive HER2 negative subtypes. We applied a supervised elastic net penalized logistic regression model to predict PIK3CA mutations from gene expression data. This regression approach was applied to predict modeling using the TCGA pan-cancer dataset. Approximately 10,000 cases were available for PIK3CA mutation and mRNA expression data. In 10-fold cross-validation, the model with $\\lambda$ = 0.01 and $\\alpha$ = 1.0 (ridge regression) showed the best performance, in terms of area under the receiver operating characteristic (AUROC). The final model was developed with selected hyper-parameters using the entire training set. The training set AUROC was 0.93, and the test set AUROC was 0.84. The area under the precision-recall (AUPR) of the training set was 0.66, and the test set AUPR was 0.39. Cancer types were the most important predictors. Both insulin like growth factor 1 receptor (IGF1R) and the phosphatase and tensin homolog (PTEN) were the most significant genes in gene expression predictors. Our study suggests that predicting genomic alterations using gene expression data is possible, with good outcomes.","tags":[],"title":"Prediction of PIK3CA Mutations from Cancer Gene Expression Data","type":"publication"},{"authors":[],"categories":["R"],"content":" yaml --- mainfont: NanumGothic output: pdf_document: latex_engine: xelatex --- The mainfont is the LaTex option. The argument is a font family. The exact names of the font family can be found in the fonts folder. Expand the header of the fonts folder. NanumGothic is the exact name of the font family.\nThe font family should be Editable embedding type (https://docs.microsoft.com/en-us/typography/opentype/spec/os2#fstype).\nThe LaTex engine should be xelatex.\nLet’s use another Korean font on pdf generated by rmarkdown.\nYou can use Roboto google font with\nheader-includes: - \\usepackage[sfdefault]{roboto} - \\usepackage[T1]{fontenc} output: pdf_document: latex_engine: pdflatex mainfont: roboto  ","date":1603756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603796166,"objectID":"0079cfdb451499bfa4e38cde47eee7a8","permalink":"/post/2020-10-27-use-korean-font-in-rmarkdown/","publishdate":"2020-10-27T00:00:00Z","relpermalink":"/post/2020-10-27-use-korean-font-in-rmarkdown/","section":"post","summary":"yaml --- mainfont: NanumGothic output: pdf_document: latex_engine: xelatex --- The mainfont is the LaTex option. The argument is a font family. The exact names of the font family can be found in the fonts folder. Expand the header of the fonts folder. NanumGothic is the exact name of the font family.\nThe font family should be Editable embedding type (https://docs.microsoft.com/en-us/typography/opentype/spec/os2#fstype).\nThe LaTex engine should be xelatex.\nLet’s use another Korean font on pdf generated by rmarkdown.","tags":["R","RStudio","rmarkdown"],"title":"Use Korean font in pdf generated from rmarkdown on Windows","type":"post"},{"authors":[],"categories":["Math","Machine learning"],"content":" Convolution is a vector operation on two vectors.\n\\[ Convolution \\\\ c * d = d*c \\\\ (c*d)_n = \\Sigma_{i+j} c_i d_j = \\Sigma_i c_i d_{n-i}.\\] This is multiplying polynomials. The parameters of multiplied polynomial become convolution of two polynomials. Fourier transformation expands x base to infinite exponential basis \\(e^{iwk}\\). The multiplication on x (time) space becomes convolutionn on k (frequency) space.\nIf time space is periodic, its Fourier transformation is discrete i.e. Fourier series. If time space is non-periodic, its Fourier transformation is continuous Fourier transformation.\nThe Fourier transformation is dual. The relations of multiplication and convolution and periodic and discrete are dual in time space and frequency space.\nFourier transformation is changing basis. The changing basis can be done by inner product (for vector space) or integration (function space) with new basis in which are we want move to space. This is why Fourier transformation coefficients calculated by integration with function multiplying basis \\(e^{iwk}\\).\n","date":1603324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603341262,"objectID":"fdc8ba4f3e322555e0c6ca942ee7ce09","permalink":"/post/convolution-and-fourier-transformation/","publishdate":"2020-10-22T00:00:00Z","relpermalink":"/post/convolution-and-fourier-transformation/","section":"post","summary":"Convolution is a vector operation on two vectors.\n\\[ Convolution \\\\ c * d = d*c \\\\ (c*d)_n = \\Sigma_{i+j} c_i d_j = \\Sigma_i c_i d_{n-i}.\\] This is multiplying polynomials. The parameters of multiplied polynomial become convolution of two polynomials. Fourier transformation expands x base to infinite exponential basis \\(e^{iwk}\\). The multiplication on x (time) space becomes convolutionn on k (frequency) space.\nIf time space is periodic, its Fourier transformation is discrete i.","tags":["Gilbert Strang","Machine learning","Math","Linear algebra"],"title":"Convolution and Fourier transformation","type":"post"},{"authors":[],"categories":["Convex optimization","Math","Machine learning"],"content":" The optimization problem have two components that are objective function \\(f_0 : \\mathbb R ^n \\rightarrow \\mathbb R\\) and the constraints. The objective function and constraints keep in check each other and make balance at saddle point i.e. optimal point. The dual (Lagrange) problem of the optimal problem also solve the optimization problem by making low boundary.\nThe dual problem can be explained as a conjugate function \\(f^* = \\sup (x^Ty-f(x))\\). The Lagrangian is \\(L(x, \\lambda, \\nu) = f_0(x) + \\lambda f_1, + \\nu f_2\\) where \\(f_0\\) is the objective function, \\(f_1\\) is inequality constraints and \\(f_2\\) is equality constraints. The Lagrangian function is \\(g(\\lambda,nu) = \\inf_{x}L(x, \\lambda, \\nu) = \\inf_{x}(f_0(x) + \\lambda f_{1} + \\nu f_{2})\\). The second and third term of the Lagrangian function is can be rewriten as an inner product form \\(x^{T}h(\\lambda) + x^{T}i(\\nu)\\) and constant term with \\(\\lambda\\) and \\(\\nu\\). Then the inner product term \\(x^{T}h(\\lambda) + x^{T}i(\\nu)\\) and objective term becomes a conjugate function.\nThe conjugate function \\(f^*(x)\\) is similar in terms of balance and saddle point.\n","date":1599955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599946649,"objectID":"ae970f28e0c4b99df947bc6686c222f0","permalink":"/post/lagrange-dual-problem-and-conjugate-function/","publishdate":"2020-09-13T00:00:00Z","relpermalink":"/post/lagrange-dual-problem-and-conjugate-function/","section":"post","summary":"The optimization problem have two components that are objective function \\(f_0 : \\mathbb R ^n \\rightarrow \\mathbb R\\) and the constraints. The objective function and constraints keep in check each other and make balance at saddle point i.e. optimal point. The dual (Lagrange) problem of the optimal problem also solve the optimization problem by making low boundary.\nThe dual problem can be explained as a conjugate function \\(f^* = \\sup (x^Ty-f(x))\\).","tags":["Convex optimization","Deep Learning","Machine learning","Math","Limit"],"title":"Lagrange dual problem and conjugate function","type":"post"},{"authors":[],"categories":["Math","Machine learning","Convex optimization"],"content":" The purpose of approximation is finding optimal point \\(x^*\\) i.e. \\(\\nabla F(x^*) = 0\\). We need a step/search direction \\(\\Delta x\\) and step size \\(t\\). Taylor approximation has polynomial arguments that is a step and parameters of derivatives at the start point. The first degree of Taylor approximation has one adding term from start point \\((x_0, F(x_0))\\). The adding term \\(\\nabla F(x) \\Delta x\\) is consistent with a parameter (gradient \\(\\nabla F(x)\\)) and a argument (step \\(\\Delta x\\)). The Taylor approximation does approximate \\(F(x + \\Delta x)\\) for any search direction \\(\\Delta x\\). We want to choose \\(\\Delta x\\) for the direction to the optimal point.\nThe adding term of Taylor approximation \\(\\nabla F(x) \\Delta x\\) have level curve (level line). The smallest Euclidean norm of the level curve is achieved at the tangent. The gradient descent set the step to the gradient \\(\\nabla F(x)\\). This makes the adding term biggest with Euclidean norm \\(\\Vert \\nabla F(x) \\Vert^2\\) i.e. dual norm \\(\\Vert \\nabla F(x) \\Vert_*\\).\nNewton’s method is second degree of Taylor approximation \\(F(x_0+\\Delta x) \\approx F(x_0) + \\nabla F(x) \\Delta x + 1/2\\Delta x^T H \\Delta x\\). We want to find \\(\\Delta x\\) to minimize the second degree of Taylor approximation. In this case, the minimizing step is tangent of first adding term \\(\\nabla F(x) \\Delta x\\) and second adding term \\(\\Delta x^T H \\Delta x\\) i.e. Steepest descent in H norm \\(\\Vert \\cdot \\Vert _H\\). The newton’s method can be thought as approximation of gradient \\(\\nabla F(x)\\). \\(\\nabla F(x_0 + \\Delta x) \\approx \\nabla F(x_0) + H \\Delta x = 0,\\ \\Delta x = -H^{-1} \\nabla F(x_0)\\). This is also the derivative of second degree of Taylor approximation with respect to \\(\\Delta x\\).\nBut the Taylor approximation is local. In addition to a step, a step size is needed. A step size determines how far the step taken. Backtracking line search has two constant parameters 0 \u0026lt; \\(\\alpha\\) \u0026lt; 0.5, 0 \u0026lt; \\(\\beta\\) \u0026lt; 1. The approximation is below the convex function. \\(\\alpha\\) tilts the slope i.e. gradient upside and the tilted approximation meets the convex function. \\(\\beta\\) is the update rate of the step size until the the amount of the step is less than the point that tilted approximation meeets the convex function.\n","date":1599177600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599216057,"objectID":"3977da296c7b28520d2c26c5b09ef3db","permalink":"/post/approximation/","publishdate":"2020-09-04T00:00:00Z","relpermalink":"/post/approximation/","section":"post","summary":"The purpose of approximation is finding optimal point \\(x^*\\) i.e. \\(\\nabla F(x^*) = 0\\). We need a step/search direction \\(\\Delta x\\) and step size \\(t\\). Taylor approximation has polynomial arguments that is a step and parameters of derivatives at the start point. The first degree of Taylor approximation has one adding term from start point \\((x_0, F(x_0))\\). The adding term \\(\\nabla F(x) \\Delta x\\) is consistent with a parameter (gradient \\(\\nabla F(x)\\)) and a argument (step \\(\\Delta x\\)).","tags":["Convex optimization","Deep Learning","Machine learning","Math"],"title":"Approximation","type":"post"},{"authors":[],"categories":["Math","Machine learning"],"content":" Bases are the central idea of linear algebra. An invertable square matrix has eigenvectors. A symetric matrix has orthogonal eigenvectors with non-negative eigenvalues, i.e. positive semidefinite. A matrix has two types of singular vectors, left and right signular vectors, \\(A=U\\Sigma V^{T}\\).\nWhen we think the matrix \\(A\\) is data points of rows \\(A=U\\Sigma V^{T}\\) like data table, The right singular vectors \\(V\\) build bases, the sigular values \\(\\Sigma\\) are magnitude of the bases and the left singular values \\(U\\) becomes new data points on new bases. The new data points \\(U\\) are orthonormal.\nWhen we think the matrix \\(A\\) is a system of linear transformation \\(Ax=b,\\ U\\Sigma V^{T}x=b\\), a vector \\(x\\) is repositioned on right singular vector coordinates \\(V\\) then the coordinates are multiplied by \\(\\Sigma\\) and finally linear transformed by left singular vector \\(U\\).\nA matrix is sum of rank one singular matrix. \\[A = \\sigma_{1} u_{1}u_{1}^{T} + \\cdots + \\sigma_{k} u_{k}u_{k}^{T}\\] The Eckart-Young theorem finds closest low-rank matrix \\(A_k\\).\nIn symetric matrix, the bases (right singular vectors) and it’s value on the bases (left singular vectors) are same. Reproducing kernel hilbert space has same values on it’s base functions.\nRayleigh quotient $R(x) = {{x^{T}Sx} } $ has maximum \\(\\lambda_{1}\\) at the eigen vector \\(q_{1}\\) and saddle points at \\(x=q_{k},\\ \\frac{\\partial R}{\\partial x_{i}} = 0\\). The second eigenvector can be found by Lagrangian optimization problum maximizing \\(\\ R(x)\\) s.t. \\(q_{1} = 0\\).\nPseudoinversion \\(A^{+}\\) process does first inversing value with \\(U^{T}\\), and scale with \\(\\Sigma ^{+}\\) and followed by reversing axis \\(V^{T}\\).\nWhen \\(Ax=b\\) has many solutions, minimizing \\(\\lVert A \\rVert\\) s.t. \\(Ax=b\\) can be best solution. The \\(L_{1}\\) norm has sparse solution.\n","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596068753,"objectID":"2e1cad1018195415c18f7e55b9500779","permalink":"/post/singular-vector-decomposition/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/post/singular-vector-decomposition/","section":"post","summary":"Bases are the central idea of linear algebra. An invertable square matrix has eigenvectors. A symetric matrix has orthogonal eigenvectors with non-negative eigenvalues, i.e. positive semidefinite. A matrix has two types of singular vectors, left and right signular vectors, \\(A=U\\Sigma V^{T}\\).\nWhen we think the matrix \\(A\\) is data points of rows \\(A=U\\Sigma V^{T}\\) like data table, The right singular vectors \\(V\\) build bases, the sigular values \\(\\Sigma\\) are magnitude of the bases and the left singular values \\(U\\) becomes new data points on new bases.","tags":["Deep Learning","Linear algebra","Gilbert Strang"],"title":"Singular vector decomposition","type":"post"},{"authors":[],"categories":["Math","Machine learning"],"content":" This is a note for part III of Linear Algebra and learning from data, Gilbert Strang\nThe main themes are sparsity (Low rank), Information theory (compression), and of course linear transformation.\nA full rank matrix is inefficient. Finding low lank matrix which is close with original matrix can save computation.\nThe rank one matrix \\(uv^{T}\\) is a unit of a matrix. The full rank matrix can be decomposed by sum of rank one matrices i.e. singular vector decomposition.\nSherman–Morrison formula suggests update rule for adding rank one matrix to the original matrix.\n\\[(A + \\mathbf{u} \\mathbf{v}^{T})^{-1} = A^{-1} - \\frac{A^{-1} \\mathbf{u} \\mathbf{v}^{T}A^{-1}}{1 + \\mathbf{v}^{T} A^{-1} \\mathbf{u}}\\]\nThe matrix norm is associated with singular value, \\(\\sigma\\).\nThe point is the unit of matrix is the rank one matrix, specially outer product of singular vectors \\(uv^{T}\\). \\(uv^{T}\\) is a coordinate of the matrix space and singular value \\(\\sigma\\) is a point on the coordinate.\nSystem, Inner product, \\(A^{T}A\\), Steady state equilibrium, dual\nA system has a law. The observations follow the law. The state set by the system’s law. The state has two variables.\n\\[ Ax=b \\;(1)\\\\ Y= \\beta X \\; (2)\\\\ \\hat{x} = \\frac {A^{T}b}{(A^{T}A) \\; (3)\\]\nEquation (1) is observations, (2) is a system, (3) is fit the observations to the system. \\(A^{T}A\\) is a steady state equilibrium. \\(A\\) and \\(A^{T}\\) are dual. \\(x\\) and \\(b\\) are dual.\n","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594712628,"objectID":"7e82d6b798f5f1108bdc24b6cae568ce","permalink":"/post/low-rank-matrix-and-compressed-sensing/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/post/low-rank-matrix-and-compressed-sensing/","section":"post","summary":"This is a note for part III of Linear Algebra and learning from data, Gilbert Strang\nThe main themes are sparsity (Low rank), Information theory (compression), and of course linear transformation.\nA full rank matrix is inefficient. Finding low lank matrix which is close with original matrix can save computation.\nThe rank one matrix \\(uv^{T}\\) is a unit of a matrix. The full rank matrix can be decomposed by sum of rank one matrices i.","tags":["Gilbert Strang","Linear algebra"],"title":"Low rank matrix and compressed sensing","type":"post"},{"authors":[],"categories":["Math","Machine learning"],"content":" The meaning of \\(A^{T}\\)\n Steady state equilibrium Graph Laplacian matrix \\(A^{T}CA\\) Differential equation and Laplacian matrix Derivative is a graph without branch. Row space and column space are dual. \\(A\\) and \\(A^{T}\\) are dual.  ref) Linear algebra and learning from data, Part IV, Gilbert Strang\n","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593470704,"objectID":"190a0647b042d8e7c4cceedf27f0067b","permalink":"/post/steady-state-equilibrium/","publishdate":"2020-06-30T00:00:00Z","relpermalink":"/post/steady-state-equilibrium/","section":"post","summary":"The meaning of \\(A^{T}\\)\n Steady state equilibrium Graph Laplacian matrix \\(A^{T}CA\\) Differential equation and Laplacian matrix Derivative is a graph without branch. Row space and column space are dual. \\(A\\) and \\(A^{T}\\) are dual.  ref) Linear algebra and learning from data, Part IV, Gilbert Strang","tags":["Deep Learning","Math"],"title":"Steady state equilibrium","type":"post"},{"authors":[],"categories":["Math"],"content":" Differential equations describe the change of state. The change relates to the state. The solutions of the differential equations are the status equations. The initial conditions set the time \\(t\\) and status \\(y\\). The boundary conditions are the value of boundary \\(y_0\\) and \\(y_1\\).\n \\(dy \\over dt\\) \\(= ay + q(t)\\) starting from \\(y(0)\\) at $t=0. inital conditions \\(t = 0\\) and \\(y=1\\)\n \\(q(t)\\) is a input and \\(y(t)\\) is a response. If \\(q(t)\\) is delta function, the response is said Impulse response \\[y\u0026#39; -ay = \\delta (t) \\\\ y(t)=e^{at}\\].\nThe solutions are combination of particular solution and null solution \\(y = y_t + y_n\\). The solution includes \\(e^{at}\\). The differential equations can not be solved like polynomial equations, because the arguments of the differentia equation relate to each other by calculus in the background of the equation. They can not be treated as just different arguments. The Fourier transformation puts the \\(y\\) and its derivative \\(y\u0026#39;\\) in the same functional space (Hilbert space). This transformation makes the differential equation problem to simple arithmetic problem.\n Fourier transformation \\(F(x) = \\Sigma ^{\\infty}_{n=-\\infty} c_{n}e^{inx}\\)\n The basis of the Fourier transformation is \\(e^{inx}\\). If the coefficients of the basis \\(c_{n}\\) decay fater, \\(F(x)\\) becomes smooth. If the coefficients are constant, \\(F(x)\\) is delta function \\(\\delta(x)\\).\nThe derivative \\(dy \\over dt\\) is an linear transformation operator, i.e. inner product, because the \\(y\\) and \\(y\u0026#39;\\) are in functional space with same basis. The defivative can be represented as a matix \\(A\\). The derivative matrix is antisymetric i.e. \\(A^T = -A\\) and the minus second derivative matrix \\(-d^{2}/dx^{2}\\) is symetic positive definite. \\(AAf = -A^{T}Af\\). The meaning of transverse of a matrix is \\((Ax)^{T}y = x^{T}(A^{T}y)\\). Dual and inner product\nSecond differnce matrix K\n The second difference matrix solves discrete differential equations. The N eigenvectors of K are \\(y_{n} = (sin\\ n\\pi \\Delta x, sin\\ 2n\\pi \\Delta x,\\ ..., sin\\ Nn\\pi \\Delta x)\\). The N eigen values of K are the positive numbers \\(\\lambda_{n} = 2-2cos {n \\pi \\over N+1}\\).\nHow does exponent \\(i\\) mean in \\(e^i\\)? The exponent makes multiplication to addition. What does an imaginary exponent mean? The imaginary exponent tilts the value to a complex plane. If the base is natural base \\(e\\), the value of \\(e^i\\) is in the unit circle of a complex plane. The cycle is \\(2 \\pi\\).\nThe Fourier transformation for solving the difference equation provoked the subject of functional analysis 200 years ago.\nReference\nDifferential Equations and Linear Algebra, Gilbert Strang\n","date":1591228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591221640,"objectID":"11baa4918e33d0d46430fc79eeaf82bb","permalink":"/post/differential-equations-and-fourier-transformation/","publishdate":"2020-06-04T00:00:00Z","relpermalink":"/post/differential-equations-and-fourier-transformation/","section":"post","summary":"Differential equations describe the change of state. The change relates to the state. The solutions of the differential equations are the status equations. The initial conditions set the time \\(t\\) and status \\(y\\). The boundary conditions are the value of boundary \\(y_0\\) and \\(y_1\\).\n \\(dy \\over dt\\) \\(= ay + q(t)\\) starting from \\(y(0)\\) at $t=0. inital conditions \\(t = 0\\) and \\(y=1\\)\n \\(q(t)\\) is a input and \\(y(t)\\) is a response.","tags":["Analysis","Functional analysis","Machine learning","Math"],"title":"Differential equations and Fourier transformation","type":"post"},{"authors":[],"categories":["Math","Information Theory"],"content":" Information relates to uncertainty. The Shannon information content of an outcome \\(x\\) is \\(h(x)=-log_{2}P(x)\\). The rare event has larger information than a common event. The unit of information is a bit (binary digit). Coding is a mapping from an outcome of an ensemble to binary digits \\(\\{0,1\\}^+\\). A symbol code is a code for a single ensemble. A block code is a code for a sequence ensemble. A set of sequences of the ensemble has a typical subset. The cardinality of a typical set is \\(2^{H_{2}X}\\). We can reduce a code length by mapping codes to only a typical set (the source coding theorem). The prefix code is an optimal symbol code. The Kraft inequality is the condition of prefix code \\(\\Sigma_{i}2^{-l_{i}} \\le 1\\).\nThe noisy-channel coding theorem describes the possible rate and block code length \\(N\\). If the block code length \\(N\\) is long enough, the channel looks like the noisy typewriter and arbitrary block error rate can be achieved with rate. The maximum rate is the capacity \\(C\\) of the channel. If the rate is small enough, the typical set of the output of the channel can be mapped for the typical set of input without overlap.\n","date":1590883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590878696,"objectID":"9c2d1a777807e73db16926c07a17213d","permalink":"/post/information/","publishdate":"2020-05-31T00:00:00Z","relpermalink":"/post/information/","section":"post","summary":"Information relates to uncertainty. The Shannon information content of an outcome \\(x\\) is \\(h(x)=-log_{2}P(x)\\). The rare event has larger information than a common event. The unit of information is a bit (binary digit). Coding is a mapping from an outcome of an ensemble to binary digits \\(\\{0,1\\}^+\\). A symbol code is a code for a single ensemble. A block code is a code for a sequence ensemble. A set of sequences of the ensemble has a typical subset.","tags":["Information theory","Math","Machine learning"],"title":"Information","type":"post"},{"authors":[],"categories":["R"],"content":" This HUGO academic theme blog is managed by blogdown. (https://bookdown.org/yihui/blogdown/other-themes.html) The HUGO theme needs to transform bib file to each reference.md files. This can be done by bib2academic rpackage. (https://github.com/petzi53/bib2academic) For the featured publication, add featured: true in the reference.md file.\n","date":1587340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587366042,"objectID":"04ec0e9762cf3e26b55f122905a750b6","permalink":"/post/managing-pulications-of-hugo-academic-blog-in-rstudio/","publishdate":"2020-04-20T00:00:00Z","relpermalink":"/post/managing-pulications-of-hugo-academic-blog-in-rstudio/","section":"post","summary":"This HUGO academic theme blog is managed by blogdown. (https://bookdown.org/yihui/blogdown/other-themes.html) The HUGO theme needs to transform bib file to each reference.md files. This can be done by bib2academic rpackage. (https://github.com/petzi53/bib2academic) For the featured publication, add featured: true in the reference.md file.","tags":["RStudio","R","Blogdown","HUGO academic blog"],"title":"Managing pulications of HUGO academic blog in Rstudio","type":"post"},{"authors":["Hyun Jung Yoon","Jun Kang","Hyunjin Park","Insuk Sohn","Seung-Hak Lee","Ho Yun Lee"],"categories":null,"content":"","date":1586131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586131200,"objectID":"1b6471b7b7b1ed7eda252c617bec4494","permalink":"/publication/2020-04-06_yoondecipheringtumormicroenvironment2020/","publishdate":"2020-04-06T00:00:00Z","relpermalink":"/publication/2020-04-06_yoondecipheringtumormicroenvironment2020/","section":"publication","summary":"Growing evidence suggests that the efficacy of immunotherapy in non-small cell lung cancers (NSCLCs) is associated with the immune microenvironment within the tumor. We aimed to explore radiologic phenotyping using a radiomics approach to assess the immune microenvironment in NSCLC. Two independent NSCLC cohorts (training and test sets) were included. Single-sample gene set enrichment analysis was used to determine the tumor microenvironment, where type 1 helper T (Th1) cells, type 2 helper T (Th2) cells, and cytotoxic T cells were the targets for prediction with computed tomographic (CT) radiomic features. Multiple algorithms were in the modeling followed by final model selection. The training dataset comprised 89 NSCLCs and the test set included 60 cases of lung squamous cell carcinoma and adenocarcinoma. A total of 239 CT radiomic features were used. A linear discriminant analysis model was selected for the final model of Th2 cell group prediction. The area under the curve value of the final model on the test set was 0.684. Predictors of the linear discriminant analysis model were skewness (total and outer pixels), kurtosis, variance (subsampled from delta [subtraction inner pixels from outer pixels]), and informational measure of correlation. The performances of radiomics on test set of Th1 and cytotoxic T cell were not accurate enough to be predictable. A radiomics approach can be used to interrogate an entire tumor in a noninvasive manner and provide added diagnostic value to identify the immune microenvironment of NSCLC, in particular, Th2 cell signatures.","tags":[],"title":"Deciphering the Tumor Microenvironment through Radiomics in Non-Small Cell Lung Cancer: Correlation with Immune Profiles","type":"publication"},{"authors":[],"categories":["Math"],"content":" \\[ f(x) = \\sum_{k=0}^\\infty c_k x^k = c_0 + c_1 x + c_2 x^2 + \\dotsb. \\]\nThis is an approximation that is a function of h and derivatives of \\(f(x)\\) are elements of parameters.\n\\(f(x \\pm h) = f(x) \\pm hf\u0026#39;(x) + \\frac{h^2}{2}f\u0026#39;\u0026#39;(x) \\pm \\frac{h^3}{6}f\u0026#39;\u0026#39;\u0026#39;(x) + O(h^4)\\)\nLet’s think about \\(\\sin(x)\\).\n\\[ f(x) = \\sin(x) \\ f(0) = 0, f\u0026#39;(x)=\\cos(x)\\ f\u0026#39;(0)=1, f\u0026#39;\u0026#39;(x)=-\\sin(x)\\ f\u0026#39;\u0026#39;(0)=0 \\]\nThus,\n\\[\\begin{align*} \\sin(x) \u0026amp;= 0 + \\frac{1}{1!}x + \\frac{0}{2!}x^2 + \\frac{-1}{3!}x^3 + \\dotsb \u0026amp;= x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\dotsb, \\end{align*}\\]\nThis is approximation. Now \\(x\\) becomes \\(h\\) and parameters calculated from derivatives of \\(f(x)\\) at \\(0\\).\n\\(f(x \\pm h) = f(x) \\pm hf\u0026#39;(x) + \\frac{h^2}{2}f\u0026#39;\u0026#39;(x) \\pm \\frac{h^3}{6}f\u0026#39;\u0026#39;\u0026#39;(x) + O(h^4)\\)\nhttps://betterexplained.com/articles/taylor-series/\n Taylor series and Newton’s bionomial theorem explain the complex exponent.\n\\[\\exp(z) = e^{z}, \\ z = a+bi \\]\nThe imaginary exponent is hard to understand intuitively. The exponential function \\(e^{x}\\) on a complex domain can be regarded as a function exp(x) that behaves like exponential function, i.e. a product of functions is addion of arguments \\(\\exp(x) \\exp(y) = \\exp(x+y)\\). The product of \\(\\exp\\) fucntion becomes addition of arguments by Newton’s binomical theorem. The costomary expression is \\(e^{x}\\). This can be done when \\(\\exp(x) = \\Sigma ^{\\infty}_{n=0} \\frac {Z^{n}}{n!}\\) The taylor series with repidly decaying pactorial coefficients \\(n!\\). This series converges absolutely for every complex \\(z\\) and converges uniformly on every bounded subset of the complex plain. Rudin’s Real and complex analysis.\n","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585604994,"objectID":"03c4e6f12bc45bda5755975735def038","permalink":"/post/taylor-series/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/post/taylor-series/","section":"post","summary":"\\[ f(x) = \\sum_{k=0}^\\infty c_k x^k = c_0 + c_1 x + c_2 x^2 + \\dotsb. \\]\nThis is an approximation that is a function of h and derivatives of \\(f(x)\\) are elements of parameters.\n\\(f(x \\pm h) = f(x) \\pm hf\u0026#39;(x) + \\frac{h^2}{2}f\u0026#39;\u0026#39;(x) \\pm \\frac{h^3}{6}f\u0026#39;\u0026#39;\u0026#39;(x) + O(h^4)\\)\nLet’s think about \\(\\sin(x)\\).\n\\[ f(x) = \\sin(x) \\ f(0) = 0, f\u0026#39;(x)=\\cos(x)\\ f\u0026#39;(0)=1, f\u0026#39;\u0026#39;(x)=-\\sin(x)\\ f\u0026#39;\u0026#39;(0)=0 \\]\nThus,\n\\[\\begin{align*} \\sin(x) \u0026amp;= 0 + \\frac{1}{1!","tags":["Analysis","Convex optimization","Machine learning"],"title":"Taylor series","type":"post"},{"authors":[],"categories":["R","Tidymodel"],"content":" https://github.com/tidymodels/recipes/issues/482\n","date":1585180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585211797,"objectID":"5bce9bfccecf6fbd3d397aa4994e4c05","permalink":"/post/my-first-github-issue/","publishdate":"2020-03-26T00:00:00Z","relpermalink":"/post/my-first-github-issue/","section":"post","summary":"https://github.com/tidymodels/recipes/issues/482","tags":["Issue","reprex"],"title":"My first github issue","type":"post"},{"authors":[],"categories":["R","Stastics","Tidymodel"],"content":" When the penalized generalize linear model (Lasso or Ridge) is processed in the tidymodel environment, finalizing the hyperparameter (lambda) and getting coefficients of the final model are confusing. Here is an example. This example predicts PIK3CA mutation status by gene expression data. TCGA breast cancer dataset is used.\nModeling library(glmnet) library(themis) set.seed(930093) cv_splits \u0026lt;- rsample::vfold_cv(trainset_ahDiff, strata = PIK3CA_T) mod \u0026lt;- logistic_reg(penalty = tune(), mixture = tune()) %\u0026gt;% set_engine(\u0026quot;glmnet\u0026quot;) rec \u0026lt;- recipe(PIK3CA_T ~ ., data = trainset_ahDiff) %\u0026gt;% step_BoxCox(all_numeric()) %\u0026gt;% step_dummy(HISTOLOGICAL_DIAGNOSIS) %\u0026gt;% step_center(all_numeric()) %\u0026gt;% step_scale(all_numeric()) %\u0026gt;% step_smote(PIK3CA_T) wfl \u0026lt;- workflow() %\u0026gt;% add_recipe(rec) %\u0026gt;% add_model(mod) glmn_set \u0026lt;- parameters(penalty(range = c(-5,1), trans = log10_trans()), mixture()) glmn_grid \u0026lt;- grid_regular(glmn_set, levels = c(7, 5)) ctrl \u0026lt;- control_grid(save_pred = TRUE, verbose = TRUE)  Grid parameter search on 10-fold cross-validation with 5 repeats\n Dummy variable to control for histologic subtype   Select best parameter glmn_tune \u0026lt;- tune_grid(wfl, resamples = cv_splits, grid = glmn_grid, metrics = metric_set(roc_auc), control = ctrl) best_glmn \u0026lt;- select_best(glmn_tune, metric = \u0026quot;roc_auc\u0026quot;)  Finalizing wfl_final \u0026lt;- wfl %\u0026gt;% finalize_workflow(best_glmn) %\u0026gt;% fit(data = trainset_ahDiff) finalize_workflow() finalizes the model with selected optimal hyperparameters. However, the glmnet fits any lambda, not the indicated lambda. This was discussed at https://github.com/tidymodels/parsnip/issues/195. The glmnet is more efficient to fit all lambda than a single lambda. Thus tidymodel ignores the indicated lambda. This made the first confusion. The finalization can be finalized by predict in tidymodel environment. Finalize with predict. Note the last argument penalty = 1 of stats::predict(wfl_final, type = \"prob\", new_data = trainset_ahDiff, penalty = 1).\ntrain_predict \u0026lt;- stats::predict(wfl_final, type = \u0026quot;prob\u0026quot;, new_data = trainset_ahDiff, penalty = 1) train_probs \u0026lt;- predict(wfl_final, type = \u0026quot;prob\u0026quot;, new_data = trainset_ahDiff) %\u0026gt;% bind_cols(obs = trainset_ahDiff$PIK3CA_T) %\u0026gt;% bind_cols(predict(wfl_final, new_data = trainset_ahDiff))  Performance conf_mat(train_probs, obs, .pred_class) ## Truth ## Prediction Wild Mutant ## Wild 213 45 ## Mutant 123 158 autoplot(roc_curve(train_probs, obs, .pred_Mutant, event_level = \u0026quot;second\u0026quot;)) roc_auc(train_probs, obs, .pred_Mutant, event_level = \u0026quot;second\u0026quot;) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 roc_auc binary 0.770 Because glmnet fits the whole path, there are whole coefficients in the glmnet fit object wfl_final. This was the second confusion. How to get the final model coefficients is below.\n Coefficients tidy(extract_model(wfl_final)) %\u0026gt;% filter(lambda \u0026gt; 0.98 \u0026amp; lambda \u0026lt; 1.01) ## # A tibble: 17 x 5 ## term step estimate lambda dev.ratio ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 55 -0.0630 1.00 0.123 ## 2 C4A 55 0.0587 1.00 0.123 ## 3 C5orf13 55 0.0587 1.00 0.123 ## 4 CDSN 55 0.0706 1.00 0.123 ## 5 CFB 55 0.0719 1.00 0.123 ## 6 CYP21A2 55 0.0516 1.00 0.123 ## 7 DGKE 55 -0.0709 1.00 0.123 ## 8 FGD5 55 0.0670 1.00 0.123 ## 9 GALNT10 55 0.0575 1.00 0.123 ## 10 GOLM1 55 0.0689 1.00 0.123 ## 11 GPX8 55 0.0657 1.00 0.123 ## 12 KLK11 55 0.0145 1.00 0.123 ## 13 NTN4 55 0.0578 1.00 0.123 ## 14 SMYD3 55 0.0637 1.00 0.123 ## 15 USP36 55 -0.0698 1.00 0.123 ## 16 WBP2 55 -0.0652 1.00 0.123 ## 17 HISTOLOGICAL_DIAGNOSIS_Infiltrating.Lobular.~ 55 -0.0244 1.00 0.123  ","date":1584489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584524523,"objectID":"f7e12e9249b9d8d252eb914083b249ba","permalink":"/post/tidymodel-and-glmnet/","publishdate":"2020-03-18T00:00:00Z","relpermalink":"/post/tidymodel-and-glmnet/","section":"post","summary":"When the penalized generalize linear model (Lasso or Ridge) is processed in the tidymodel environment, finalizing the hyperparameter (lambda) and getting coefficients of the final model are confusing. Here is an example. This example predicts PIK3CA mutation status by gene expression data. TCGA breast cancer dataset is used.\nModeling library(glmnet) library(themis) set.seed(930093) cv_splits \u0026lt;- rsample::vfold_cv(trainset_ahDiff, strata = PIK3CA_T) mod \u0026lt;- logistic_reg(penalty = tune(), mixture = tune()) %\u0026gt;% set_engine(\u0026quot;glmnet\u0026quot;) rec \u0026lt;- recipe(PIK3CA_T ~ .","tags":["R","RStudio","Machine learning","Demo"],"title":"Tidymodel and glmnet","type":"post"},{"authors":[],"categories":["Math"],"content":" This is a note for Elements of information theory of Thomas M. Cover.\nThe entropy (\\(H\\)) is a measure of uncertainty of a variable which is the answer to what is the ultimate data compression. Is the conditional probability \\(p(x|y)\\) considered as a probability of the “conditional variable” \\((X|Y=y)\\)? Yes, it is the subset of \\(X\\) given \\(Y=y\\). If you sum all of the subset probabilities, it becomes the cardinality of \\(X\\). Thus if you make that become 1, the conditional probability should be multiplied with \\(p(x)\\). The conditional probability is larger than joint probabilities \\(p(x,y)\\).\nLet’s think about the entropy of a joint random variable \\((X,Y)\\). If \\(X\\) and \\(Y\\) are correlated, the entries of the contingent table of \\(p(x,y)\\) are concentrated at some points that mean lager or smaller probabilities than a product of \\(p(x)\\) and \\(p(y)\\). The joint probability is a product of probability of \\(X\\), \\(p(x)\\) and conditional probability \\(p(X|Y)\\). The conditional entropy is the expectation of a random conditional variable (conditional entropy). The conditional entropy does not mean the entropy of a subset of \\(X|Y=y\\). It is a measure of uncertainty of \\(X\\) given \\(Y\\). If \\(Y\\) has the information of the \\(X\\), the entropy of \\(X|Y\\) is less than \\(X\\). The conditional entropy \\(H(X|Y)\\) is subtract the entropy of Y \\(H(Y)\\) from joint entropy \\(H(X,Y)\\). The joint probability \\(p(x,y)\\) is the product of probability of \\(Y\\) and conditional probability \\(p(x|Y=y)\\). This is chain rule of joint entropy \\(H(X,Y) = H(Y) + H(X|Y)\\).\nThe chain rule is converting a joint variable to the sum of conditional random variables. The joint variable is the sum of conditional random variables. This is can be applied in the entropy, the information, and the relative entropy.\n","date":1584230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584221480,"objectID":"6235ff59cc307a41c21765242b345419","permalink":"/post/entropy/","publishdate":"2020-03-15T00:00:00Z","relpermalink":"/post/entropy/","section":"post","summary":"This is a note for Elements of information theory of Thomas M. Cover.\nThe entropy (\\(H\\)) is a measure of uncertainty of a variable which is the answer to what is the ultimate data compression. Is the conditional probability \\(p(x|y)\\) considered as a probability of the “conditional variable” \\((X|Y=y)\\)? Yes, it is the subset of \\(X\\) given \\(Y=y\\). If you sum all of the subset probabilities, it becomes the cardinality of \\(X\\).","tags":["Information theory","Math"],"title":"Entropy","type":"post"},{"authors":[],"categories":["Math","Machine learning"],"content":" This is summary of Boyd convex optimization. Steepest descent method is a convex optimization algorithm. The normalized steepest descent direction \\(x_{nsd}\\) is a vector of unit ball of a norm that extends in the direction \\(-\\nabla f(x)\\). The inner product of \\(x_{nsd}\\) and \\(-\\nabla f(x)\\) is maximized. The first order Taylor approximation of \\(f(x+v) = f(x) + \\nabla f(x)^{T} v\\) is most efficient when \\(v = x_{nsd}\\).\nThe \\(x_{nsd}\\) is unnormalized into \\(x_{sd}\\). The normalization is ralated with unit ball of norm. When \\(x_{nsd}\\) is scaled with dual norm of \\(-\\nabla f(x)\\), the second term of Taylor approximation \\(\\nabla f(x)^{T} x_{sd}\\) becomes convex (squre of dual norm of gradient of \\(f(x)\\)). The unnormalized \\(x_{sd}\\) the amount of movement of approximation because the inner product of gradient of \\(f(x)\\) and unnormalized steepest descent direction is squre of dual norm of gradient.\nThe dual norm of gradient \\(\\lVert \\nabla f(x) \\rVert\\) is main subject of this post. The simplest dual is a complement of a set. The \\((C^c)^c\\) is \\(C\\). If \\(C\\) is small, \\(C^C\\) is large and vice versa. The dual cone is related to inner product and non-negativity. Let \\(K\\) be a cone, The set \\(K^{*} = \\{y|x^{T}y \\geq 0\\) for all \\(x \\in K\\}\\). If \\(K\\) is large, \\(K^{*}\\) is small and vice versa.\nThe dual norm \\(\\left\\lVert x \\right\\rVert _{*}\\) is \\(\\sup \\{\\, x^{T}y \\mid \\lVert y \\rVert \\leq 1 \\,\\}\\). If \\(x\\) direction is long axis of ellypsoid norm, the norm of \\(x\\) is small. But the dual norm is large because \\(\\lVert y \\rVert _{2}\\) large and vice versa.\nThe main points are the first order Taylor approximation is most efficient with ellypsoid norm when the linear approximation is \\(\\sup\\{\\nabla f(x) ^{T} x_{sd}\\}\\) which is dual norm of gradient of \\(f(x)\\).\n","date":1582070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582100354,"objectID":"db44ea11ec76f6d029914be2739e0557","permalink":"/post/duality/","publishdate":"2020-02-19T00:00:00Z","relpermalink":"/post/duality/","section":"post","summary":"This is summary of Boyd convex optimization. Steepest descent method is a convex optimization algorithm. The normalized steepest descent direction \\(x_{nsd}\\) is a vector of unit ball of a norm that extends in the direction \\(-\\nabla f(x)\\). The inner product of \\(x_{nsd}\\) and \\(-\\nabla f(x)\\) is maximized. The first order Taylor approximation of \\(f(x+v) = f(x) + \\nabla f(x)^{T} v\\) is most efficient when \\(v = x_{nsd}\\).\nThe \\(x_{nsd}\\) is unnormalized into \\(x_{sd}\\).","tags":["Convex optimization","Math"],"title":"Duality","type":"post"},{"authors":[],"categories":["Math"],"content":" This is a summary of the Boyd convex optimization book. The strong convexity assumption can be useful to explain the iterative minimization algorithms like gradient descent, steepest descent, and Newton’s method.\nThe smallest and largest eigen value of Hessian \\(m \\preceq \\nabla^{2}f(x) \\preceq M\\) with norm of gradient \\(\\| \\nabla f(x)\\|_2\\) determine the boundary of optimal value \\(p^{*}\\). The condition number of cond(\\(C_\\alpha\\)) \\(\\leq {M \\over m}\\), where \\(C_\\alpha\\) is \\(\\alpha\\)-sublevel. The condition number is ratio of largest eigen value to its smallest eigen value.\nWhen the Hessian is replaced with a constant \\(m\\) and \\(M\\), the constants make the equality of Taylor’s theorem to inequality that makes lower and upper boundaries of \\(p^*\\). The difference between the approximation and \\(p^*\\) is determined by $ f(x)$ and \\(m\\) or \\(M\\). If \\(\\nabla f(x)\\) is small and the gap is so. If Hessian (\\(m\\) or \\(M\\)) is large, the gap is small.\nBecause the second degree of Tayler’s expansion is quadratic, at near the optimal point, the \\(\\alpha\\)-sublevel is ellipsoid. The condition number cond(\\(C_{\\alpha}\\)), geometrically, represents anisometry or eccentricity\n","date":1581120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581120658,"objectID":"1d9e88b37a9d1b35b43bee8c35c0de29","permalink":"/post/strong-convexity-and-implications/","publishdate":"2020-02-08T00:00:00Z","relpermalink":"/post/strong-convexity-and-implications/","section":"post","summary":"This is a summary of the Boyd convex optimization book. The strong convexity assumption can be useful to explain the iterative minimization algorithms like gradient descent, steepest descent, and Newton’s method.\nThe smallest and largest eigen value of Hessian \\(m \\preceq \\nabla^{2}f(x) \\preceq M\\) with norm of gradient \\(\\| \\nabla f(x)\\|_2\\) determine the boundary of optimal value \\(p^{*}\\). The condition number of cond(\\(C_\\alpha\\)) \\(\\leq {M \\over m}\\), where \\(C_\\alpha\\) is \\(\\alpha\\)-sublevel.","tags":["Convex optimization","Machine learning","Math"],"title":"Strong convexity and implications","type":"post"},{"authors":[],"categories":["Machine learning","R","Stastics","Tidymodel"],"content":" Machine Learning and Tidymodel Model setting, {Parsnip} Rpackage Parsnip standardizes model specification. Tidymodel follows the concept of lazy evaluation of the tidyverse. Parsnip sets unified specifications and lately evaluates.\n Feature engineering, {Recipes} Recipes make preprocessing easy with step_() functions. Recipes after specification calculate.\n Resampling, {rsample} To choose a model and hyperparameters, we must validate the different models.\n Making hyperparameter set, {dials} The Rpackage {dials} set hyperparameter similarily with {Parsnip}. {Dials} standadize parameter of each modeling algorithm.\n Set modeling process, {Workflowr}  Fit models with hyperparameter, {tunes}   ","date":1580428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580535080,"objectID":"f4657b89a9d7022223eaeda0db96d549","permalink":"/post/tidymodel/","publishdate":"2020-01-31T00:00:00Z","relpermalink":"/post/tidymodel/","section":"post","summary":"Machine Learning and Tidymodel Model setting, {Parsnip} Rpackage Parsnip standardizes model specification. Tidymodel follows the concept of lazy evaluation of the tidyverse. Parsnip sets unified specifications and lately evaluates.\n Feature engineering, {Recipes} Recipes make preprocessing easy with step_() functions. Recipes after specification calculate.\n Resampling, {rsample} To choose a model and hyperparameters, we must validate the different models.\n Making hyperparameter set, {dials} The Rpackage {dials} set hyperparameter similarily with {Parsnip}.","tags":["Machine learning","R","RStudio","RStudio conference"],"title":"Tidymodel","type":"post"},{"authors":[],"categories":["R"],"content":" Key Note\nJ.J. Allaire\nRStudio becomes Public B Corp.\nJ.J. Allaire’s favorite book Fooled by Randomness\nRStudio has restructured as a \u0026#39;benefit corporation,\u0026#39; legally allowing it to consider the needs of its users and the #rstats community and not just its shareholders, JJ Allaire announced just now at #rstudioconf #rstudioconf2020 https://t.co/uG6SjNeLei\n\u0026mdash; Sharon Machlis (@sharon000) January 29, 2020  #Rstudio evolution #rstudioconf2020 pic.twitter.com/euZFBTpvVY\n\u0026mdash; 1LittleCoder💻 (@1littlecoder) January 29, 2020   Google AI PAIR team\nFernanda Viegas, Martin Wattenberg\nDebug your data first, not your program!\nVisualization, Hello World Image data set has faulty annotations.\nValidate your data set!!\nHigh dimensionality, MNIST data set PCA clustering.\nFairness, Different views of points can be visualized. People can understand it.\nGreat to see misclassification applied to fairness in loans! #rstudioconf2020 #rstudio #rstats #google pic.twitter.com/0TOCCegOpt\n\u0026mdash; Kyle Monahan (@kylemonahan2) January 29, 2020  If you are doing data science, you are doing user experience design - with great power comes great responsibility #rstudioconf2020 Loved this keynote! @wattenberg @viegasf pic.twitter.com/goNzLkhSUe\n\u0026mdash; Alison Presmanes Hill (@apreshill) January 29, 2020  Next big #rstudioconf2020 keynote quote that I love:\nDebug your data first, not your program!\n\u0026mdash; Hunter Glanz (@hglanz) January 29, 2020  https://pair.withgoogle.com\nAndrew Mangan, Salesforce\nAnalytics using R\nMine Cetinkaya-Rundelm, RStudio\n Shiny contest, open codes Joe Cheng, RStudio\nStyling Shiny with Sass and Bootstrap 4\nBootstrap 4 is default Shiny frame. Bootstrap 4 supports Sass which is a meta-program for CSS. {bootstraplib} makes easy to use Sass in R environment.\nThanks to @jcheng for the shoutout at #rstudioconf2020! Be sure to check out @jcheng and @cpsievert’s package bootstraplib for easy custom fonts and styling in #shiny https://t.co/hcy5zCxuAQ\n\u0026mdash; Tim Mastny (@timmastny) January 29, 2020  A nice resource for learning shiny from @_ColinFay:https://t.co/RtKU6sowqj#rstudioconf2020\n\u0026mdash; John Blischak (@jdblischak) January 29, 2020   What if we kissed 😳😳 in #rstudioconf2020 Grand Ballroom B 🙈 pic.twitter.com/UXYxH6mjWQ\n\u0026mdash; Dr. Jacqueline Nolis (@skyetetra) January 29, 2020  .@skyetetra and @heatherklus have released the OSS loadtest package! Run and analyze load tests from entirely within R\nLearn more: https://t.co/3Xq8J9jqfA #rstudioconf pic.twitter.com/LwkwO4DDP1\n\u0026mdash; David Robinson (@drob) January 29, 2020  Standing room only for @paleolimbot #rstudioconf2020 talk on programming with ggplot2! Did you know that you can put plot items into a list and add that?? pic.twitter.com/wGMEPSBIeP\n\u0026mdash; Calum You (@_calumyou) January 30, 2020  Just learned that adding NULL to a ggplot does nothing...which is super useful when writing functions that wrap ggplot. ggplot(...) + NULL is the same as ggplot(...). Thanks @paleolimbot! #rstudioconf2020\n\u0026mdash; Taylor Reiter (@ReiterTaylor) January 30, 2020   Carson Sievert, RStudio\nReproducible Shiny, Download tab, {shinymeta}\nAymen Waqar\nBuilding a native iPad dashboard\nAna Alyeska Santos, Braulio Cuandon, Biosense Webster, Inc.\nReproducible Engineering Test Reports\nJustin Juskewitch, Mayo Clinic\nTransfusion platelet selection and match for patient and documentation automation\nAlicia Schep, Outlier AI\nShe moved R from Python. {vlBuildr} API develop Altair and Vega-Lite\nTyson Barrett\nList-columns in data.table\ndata.table can easily convert list-columns\nLearn how to use list-columns with data.table from these slides from @healthandstats:https://t.co/amXG686twc#rstudioconf2020 https://t.co/CrPVDhtYgH\n\u0026mdash; John Blischak (@jdblischak) January 30, 2020  Lightning Talk\nMexican election prediction\nReally interesting talk from @TeresaOM on predicting Mexican election results from initial polling data. They\u0026#39;re in a \u0026quot;bunker\u0026quot; with no internet access, so no StackOverflow!#rstudioconf2020https://t.co/8Im6k6zusu\n\u0026mdash; John Blischak (@jdblischak) January 30, 2020  Rebecca Barter Becoming an R Blogger\nStupidly excited for #rstudioconf2020 this week! 📢 Check out my lightening talk on \u0026quot;becoming an R blogger\u0026quot; Thursday at 2:55. 👋 If you\u0026#39;d like to say hi during the conference, feel free to reach out#rstats #datascience\n\u0026mdash; Rebecca Barter (@rlbarter) January 27, 2020  Other sessions, not check-in\n🎨📊 Enjoying learning about { ggtext } and { gridtext } #rstats packages from @ClausWilke @ #rstudioconf2020https://t.co/vyqgTkTnM8https://t.co/jnnR0AvGF0 pic.twitter.com/4ew8EKqXay\n\u0026mdash; Rich Pauloo, PhD (@RichPauloo) January 30, 2020  Session: \u0026quot;Updates on Spark, MLFlow \u0026amp; the Broader ML Ecosystem\u0026quot; (including Delta Lake)\nUse Spark in R via Sparklyr ✨#rstudioconf #rstudioconf2020 pic.twitter.com/j1ITayLf8G\n\u0026mdash; Daniel ModeratelyOnline McNichol (@dnlmc) January 29, 2020  Sage advice for putting R models in production from @heatherklus and @skyetetra:\n- Avoid too many tests by only testing the most critical behavior\n- Load test to find bottlenecks\n- Give people a tool to explore and understand the model#rstudioconf2020\n\u0026mdash; John Blischak (@jdblischak) January 29, 2020  Realtime Spell Check and global replacement in @rstudio IDE 1.3!! 🥳🙌#rstudioconf2020 #rstudioconf pic.twitter.com/6cICDvWbdq\n\u0026mdash; annakrystalli (@annakrystalli) January 30, 2020  Enjoying #rstudioconf2020 . Here are the slides from the talk I gave yesterday: https://t.co/R7vxqENMN3\n\u0026mdash; Frank Harrell (@f2harrell) January 30, 2020  How to build native iPad app using R and plumber under the hood - @D_Rodziewicz @appsilon #rstudioconf2020 #rshiny pic.twitter.com/tShpA0gc7h\n\u0026mdash; Paweł Przytuła (@pawel_appsilon) January 30, 2020  Great message during the talk of @MT_statistics at the @RLadiesGlobal breakfast #rstudioconf2020 pic.twitter.com/XWevhIFP4N\n\u0026mdash; Joselyn Chavez (@josschavezf1) January 29, 2020  Some presentation highlights: (1) @W_R_Chase on graph styling: https://t.co/JVgUrhPxLm (2) @ClausWilke on formatting ggplot2 text (so now you can implement some of @W_R_Chase\u0026#39;s suggestions): https://t.co/rQX89X45dM (3) @JennyBryan on debugging in R: https://t.co/nTg2D6SCSN [2/n]\n\u0026mdash; Alex Albright (@AllbriteAllday) January 31, 2020  @fellgernon kindly tweeted me.\n#rstudioconf workshops day 1 lunch:\nJun Kang is a clinical assistant professor at a hospital in South Korea who uses R for many things from exploring data with #shiny to building predictive models@JKang1978 https://t.co/13rARrqbWs https://t.co/oG59N82o2U #rstats 3/11 pic.twitter.com/JFVTuWbrrg\n\u0026mdash; 🇲🇽 Leonardo Collado-Torres (@lcolladotor) February 2, 2020  On my latest blog post I talk about how empowering it can be when you help others make connections☺️. That is, becoming a sponsor as defined by @robinson_es. It\u0026#39;s worth it!\nThx @StefanieButland for the motivation to write this post!https://t.co/PY0KCC5yAi#rstudioconf #rstats pic.twitter.com/MUkHvmXdBD\n\u0026mdash; 🇲🇽 Leonardo Collado-Torres (@lcolladotor) February 4, 2020  And he left some inspiring post. http://lcolladotor.github.io/2020/02/03/conference-feelings-from-newbie-to-sponsor/\n ","date":1580256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580349084,"objectID":"43454a8428598d5e8756b26ba81d37f8","permalink":"/post/rstudio-conference-2020/","publishdate":"2020-01-29T00:00:00Z","relpermalink":"/post/rstudio-conference-2020/","section":"post","summary":"Key Note\nJ.J. Allaire\nRStudio becomes Public B Corp.\nJ.J. Allaire’s favorite book Fooled by Randomness\nRStudio has restructured as a \u0026#39;benefit corporation,\u0026#39; legally allowing it to consider the needs of its users and the #rstats community and not just its shareholders, JJ Allaire announced just now at #rstudioconf #rstudioconf2020 https://t.co/uG6SjNeLei\n\u0026mdash; Sharon Machlis (@sharon000) January 29, 2020  #Rstudio evolution #rstudioconf2020 pic.twitter.com/euZFBTpvVY\n\u0026mdash; 1LittleCoder💻 (@1littlecoder) January 29, 2020   Google AI PAIR team","tags":["R","RStudio","RStudio conference","Shiny"],"title":"RStudio Conference 2020","type":"post"},{"authors":[],"categories":["R","Stastics","Machine learning"],"content":" This is a note of applied machine learning workshop RStudion conference 2020\nWhy is it hard to predict (domain knowledge).\npurrr::map allows inline code.\npurrr::map and tidyr::nest covered because they are used in resample or tune.\nSkew data might be looking outlier.\nPeople look at data in many different ways like outliers, missingness, correlation, and suspicion of an important variable.\nThe ggplot is good to explore variables adding geoms changing plot.\nMachine learning is creative because you can do many different ways such as which variable should be included.\nModel workflow: imputation -\u0026gt; transformation -\u0026gt; filter -\u0026gt; model\nResampling avoids something like the garden of forking paths or p-hacking by honest feedback.\nThe tuning parameter can be estimated analytically or iteratively.\nSingle validation set ??\nResampling process questions\nSplitting data is confusing.\nThe test set split preserves distribution.\nInterval and sampling are behind the scene of resampling.\nfomular x ~ . -something to remove\nVariable role: limited (can not be applied to hierarchical in Baysian??)\nFormula and XY interface is not fit in machine learning. The recipes package is a solution.\nThe broom::glance (one-row summary of metrics, don’t trust this too much) tidy (coefficients) augment (by data points)\nThe parsnip (unified interface) is a solution to a different interface.\nHow to set specific settings using parsnip?\nMany other packages supporting parsnip. Look at the tidymodels packages.\nWhat is the difference between caret and parsnip?\nCaret~base R, parsnip~tidyverse\nThe parsnip generalizes the interfaces and is easy to extend.\nA dummy variable is confusing in the interaction of terms and how to interpret coefficiency.\nThe level with 0,0 allocation becomes a base variable in factor variable. A continuous variable can be categorized with recipe::step_discritize().\nA zero variance predictor includes no record or single value variable.\nFeature engineering problem * Dummy variable\n* Zero variance * Standardize\nCustomizing Step function\nThe first level is a reference. There are ways to change the reference level. (Ordering factor level issues)\nPeople respond positively to the recipes.\nrecipe -\u0026gt; prep -\u0026gt; juice/bake; define -\u0026gt; calculate -\u0026gt; processing (training or test set)\nThe post-processed data set goes to fit() to establish a model\nVersioning model caching?\nmod_rec \u0026lt;- recipe( Sale_Price ~ Longitude + Latitude + Neighborhood, data = ames_train ) %\u0026gt;% step_log(Sale_Price, base = 10) %\u0026gt;% # Lump factor levels that occur in # \u0026lt;= 5% of data as \u0026quot;other\u0026quot; step_other(Neighborhood, threshold = 0.05) %\u0026gt;% # Create dummy variables for _any_ factor variables step_dummy(all_nominal()) %\u0026gt;% step_nzv( starts_with (\u0026quot;Neighborhood_\u0026quot;)) preped_data \u0026lt;- prep(mod_rec) preped_data %\u0026gt;% juice() %\u0026gt;% slice(1:5) ## # A tibble: 5 x 11 ## Longitude Latitude Sale_Price Neighborhood_Co… Neighborhood_Ol… ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 -93.6 42.1 5.24 0 0 ## 2 -93.6 42.1 5.39 0 0 ## 3 -93.6 42.1 5.28 0 0 ## 4 -93.6 42.1 5.29 0 0 ## 5 -93.6 42.1 5.33 0 0 ## # … with 6 more variables: Neighborhood_Edwards \u0026lt;dbl\u0026gt;, ## # Neighborhood_Somerset \u0026lt;dbl\u0026gt;, Neighborhood_Northridge_Heights \u0026lt;dbl\u0026gt;, ## # Neighborhood_Gilbert \u0026lt;dbl\u0026gt;, Neighborhood_Sawyer \u0026lt;dbl\u0026gt;, ## # Neighborhood_other \u0026lt;dbl\u0026gt; step_dummy -\u0026gt; step_other/step_nzv()\nStep_dummy creates many dummy variables thus you should include the new dummy variables into the interaction terms or others or nzv. with starts_with() function.\nResolving skewness: Box-cox, inverse, of course, log or square root\nparsnip model object includes original model results in $fit.\nThe workflow replaces prep() -\u0026gt; juice() -\u0026gt; fit() with single call fit() and bake() -\u0026gt; predict() with predict ().\nThe workflow needs adding model specification (parsnip) and preprocessing (recipes).\nResampling is the best option to estimate the performance of a model.\nResampling splits analysis set and assessment set on training set. The final result is performance metrics.\nSelecting the resampling method relates to bias-variance trade-off. (Repeated CV)\nhttps://en.wikipedia.org/wiki/Model_selection#Criteria information criteria??\nResampling does stratified sampling.\nThe tuning metric tends to be smooth. The irregular metric result means high variance.\nhttp://appliedpredictivemodeling.com/blog/2014/11/27/vpuig01pqbklmi72b8lcl3ij5hj2qm\nResampling spends memory. The vfold_cv() has a copy of the original data.\nProcessing first or resampling first??\nResample first\nIf preprocessing is outside of resampling, You don’t know how the test set will be predicted.\nIs feature engineering stable or unstable?\nCan tune package select a good preprocessing process? Yes, it can.\nThe upsampling issues and rare important data points\nThe tuning hyperparameter (underfitting or overfitting).\nHyperparameter types grid (regular, irregular), iterative\nMaking function name: use underbar _ “Grid_regular”\nThe pros and cons of regular and non-regular grid\nThe non-regular grid efficient except some model can do trick.\nThe parsnip standardizes and it changes default parameter ranges.\nThe parameter tibble can not be subsetted. It will be issued in GitHub.\nPeople take care of the default value of parameters.\nTidymodel delays evaluation. Set first and run later.\nThe Splines fitting is wagged at the edge of the range. When trying to predict value out of range, warnings occur. Resampling can cause an error at the edge point of the assessment set.\nThere is a note column in the result object.\nThe sensitivity of parameters can be evaluated with ggplot. The scale should be adjusted when an outlier is present.\nBest fit can be choose\nDocumentation\nShow best and select best (parameter)\nTune tunes selected parameters. If you don’t tune parameters, the parameters go default value.\nThe log ridership is wired because of a bimodal distribution. It will show skewed residual or something.\n!!stations indicates the environment of the station object, the station object is defined at recipe object, not the global environment.\nRegularization wins wrapping feature selection methods in terms of efficacy.\nIf two predictors are highly correlated, the signs can change and the variance of coefficients inflates.\nL1 penalty does feature selection, the L2 penalty resolves correlation. Does mixture feature selection? Yes, the L1 component and lambda determine how many variables are kicked out, except pure ridge regression (ie. pure L2 penalty).\nNormalize or standardize on dummy variables?\nLambda is a more important parameter than alpha in glm.\nParallelism issue. GPU is good at linear algebra. Parallelism consumes memory because they copy data. Tuning is advantaged with parallelism because it uses for a loop. Unix is better than Windows in terms of parallelism.\nInner join makes prediction tibble subsetting best.\nRepeated CV residual can be estimated with average predicting values.\nGCV is used to pruning the point.\nIs MARS greedy? Semi-greedy.\nMARS is struggling with colinearity. Use step_pca.\nBayesian process, Gaussian process, Kernel function selection\nMARS hyperparameter space is high dimensional, thus the Gaussian process is better than the grid method in terms of efficiency. Grid methods for the Chicago data MARS model need more than 4000 points of the grid, although the grid search can use a parallel process.\nThe Bayesian parameter searching process can be updated and pause.\nClassification Hard prediction vs soft prediction (probability)\nAccuracy can be estimated with hard prediction and ROC can be produced on soft prediction.\nFeature hashing is difficult to understand.\nrecipe can be tune.\nC5.0 is boost_tree.\nGitter discussion https://gitter.im/conf2020-applied-ml/community/archives/2020/01/28\n","date":1579996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580112115,"objectID":"33485e9b381232d8e987a214c15c850e","permalink":"/post/applied-machine-learning-workshop-rstudio-conference-2020/","publishdate":"2020-01-26T00:00:00Z","relpermalink":"/post/applied-machine-learning-workshop-rstudio-conference-2020/","section":"post","summary":"This is a note of applied machine learning workshop RStudion conference 2020\nWhy is it hard to predict (domain knowledge).\npurrr::map allows inline code.\npurrr::map and tidyr::nest covered because they are used in resample or tune.\nSkew data might be looking outlier.\nPeople look at data in many different ways like outliers, missingness, correlation, and suspicion of an important variable.\nThe ggplot is good to explore variables adding geoms changing plot.","tags":["Machine learning","R","RStudio conference","RStudio"],"title":"Applied Machine Learning Workshop RStudio Conference 2020","type":"post"},{"authors":["In Hye Song","Sook-Hee Hong","Kyo Yeong Lee","Jun Kang","Sung Hak Lee","Jieun Lee","Ahwon Lee"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e5c1fc3cd7f3ad14bc76507958325097","permalink":"/publication/2020-01-01_songnextgenerationsequencing2020/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020-01-01_songnextgenerationsequencing2020/","section":"publication","summary":"Development of molecular technology has led to the expansion of next generation sequencing (NGS) in area of diagnostic pathology. Here we present a case in which a lung tumor, which resembled an atypical carcinoid tumor, was revealed as metastatic breast cancer by next generation sequencing. A 50-year-old female, who had received modified radical mastectomy for breast cancer, presented with a 2.1 cm sized lung mass. The mass was well-defined, well-enhanced, and showed endobronchial component by computed tomography. Under the impression of carcinoid tumor, right upper lobectomy was performed. Tumor cells were immunohistochemically positive for chromogranin and CD56, but negative for cytokeratin 7 and GCDFP-15. Initially, the patient was diagnosed with atypical carcinoid tumor. However, subsequent NGS test revealed GATA3 mutation (p.Ala333fs) of the lung tumor. After a thorough review of literature and public cancer genome data about GATA3 mutation, the diagnosis was revised to metastatic invasive carcinoma from breast.","tags":[],"title":"Next Generation Sequencing Can Be Helpful in Histologic Diagnosis: A Case Report of Metastatic Breast Cancer Mimicking Atypical Carcinoid Tumor of Lung","type":"publication"},{"authors":["Min A. Lee","Jun Kang","Ho Yun Lee","Wooil Kim","Insuk Shon","Na Young Hwang","Hong Kwan Kim","Yong Soo Choi","Jhingook Kim","Jae Ill Zo","Young Mog Shim"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"8dee4c04e703c43ce02f6e032546b6ad","permalink":"/publication/2020-01-01_leespreadairspaces/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020-01-01_leespreadairspaces/","section":"publication","summary":"Background Spread through air spaces (STAS) has recently been demonstrated to exhibit a negative impact on lung adenocarcinoma prognosis. However, most of these studies investigated STAS in nonmucinous adenocarcinoma. Here, we investigated the incidence of STAS in invasive mucinous adenocarcinoma (IMA) of the lung and evaluated whether tumor STAS was a risk factor of disease recurrence in IMA. We also examined clinicoradiologic factors in patients with IMA harboring STAS. Methods We reviewed pathologic specimens and imaging characteristics of primary tumors from 132 consecutive patients who underwent surgical resection for IMA to evaluate STAS. Patients with and without STAS were compared with respect to clinical characteristics as well as computed tomography (CT) imaging using logistic regression. The relationships between all variables including STAS and survival were analyzed. Results Among a total of 132 patients, full pathologic specimens were available for 119 patients, and STAS was observed in 86 (72.3\\%). IMA patients with STAS were significantly associated with older age, presence of lobulated and spiculated margins on CT scan (P = 0.009, P = 0.006, and P = 0.027). In multivariate analysis for overall survival (OS), STAS was a borderline independent poor prognostic predictor (P = 0.028). Older age, history of smoking, higher T stage, presence of lymph node metastasis, and consolidative morphologic type remained independent predictors for OS. Conclusions STAS was associated with reduced OS and was a borderline independent poor prognostic factor in IMA. IMA with STAS was associated with older age and presence of lobulated and spiculated margins on CT scan. Key points Significant findings of the study Compared with other subtypes, IMA shows a higher incidence of STAS, which is an independent poor prognostic predictor even in IMA. Lobulated and spiculated margins on CT are associated with STAS. What this study adds Considering that STAS can carry the potential for aerogenous metastasis, predicting STAS using preoperative surrogate CT imaging is desirable to avoid limited resection.","tags":[],"title":"Spread through Air Spaces (STAS) in Invasive Mucinous Adenocarcinoma of the Lung: Incidence, Prognostic Impact, and Prediction Based on Clinicoradiologic Factors","type":"publication"},{"authors":[],"categories":["Math"],"content":" There is a homology between a line segment and a convex set. It is helpful to understand the convex set. A line, a line segment, and one sideline has homology to an affine set, a convex set, and a cone. A line is \\(\\{y|y=\\theta_1 x_1 + \\theta_2 x_2, \\theta_1 + \\theta_2 = 1\\}\\) if \\(\\theta_1, \\theta_2 \\in \\mathbb{R}\\), a line segment is if \\(\\theta_1, \\theta_2 \u0026gt; 0\\) and an one side line if any \\(\\theta_1, \\theta_2 \u0026lt; 0\\).\nA set \\(C\\) is affine set if $ y C$ and \\(\\{y|y=\\theta_1 x_1 + \\theta_2 x_2, \\theta_1 + \\theta_2 = 1, x_1, x_2 \\in C, \\theta_1, \\theta_2 \\in \\mathbb{R} \\}\\). a convex set is if \\(\\theta_1, \\theta_2 \u0026gt; 0\\) and a cone if any \\(\\theta_1, \\theta_2 \u0026lt; 0\\).\nAn affine set is a convex set. But all convex set is not an affine set. It looks the convex set has a stronger condition than affine set i.e. positivity of \\(\\theta\\). But in fact, the convex set has a stronger condition on what it should contain. Because an affine set contains more than a convex set, an affine set satisfies the condition to be a convex set.\n","date":1577404800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577429160,"objectID":"06e78f2e66f46561ee7d798b1a2a24f5","permalink":"/post/convex-set/","publishdate":"2019-12-27T00:00:00Z","relpermalink":"/post/convex-set/","section":"post","summary":"There is a homology between a line segment and a convex set. It is helpful to understand the convex set. A line, a line segment, and one sideline has homology to an affine set, a convex set, and a cone. A line is \\(\\{y|y=\\theta_1 x_1 + \\theta_2 x_2, \\theta_1 + \\theta_2 = 1\\}\\) if \\(\\theta_1, \\theta_2 \\in \\mathbb{R}\\), a line segment is if \\(\\theta_1, \\theta_2 \u0026gt; 0\\) and an one side line if any \\(\\theta_1, \\theta_2 \u0026lt; 0\\).","tags":["Convex optimization","Math"],"title":"Convex set","type":"post"},{"authors":[],"categories":["Math","Stastics"],"content":" Finally arrive at reproducing kernel Hilbert space. https://nzer0.github.io/reproducing-kernel-hilbert-space.html\nThe above post introduces RKHS in Korean. It was helpful. I had struggled to understand some concepts in RKHS. What does mean Hilbert space in terms of feature expansion? (\\(f:\\mathcal{X} \\to \\mathbb{R}\\), \\(f \\in \\mathcal{H}_K\\)) It was confusing the difference between \\(f\\) and \\(f(x)\\). \\(f\\) means the function in Hilbert space and \\(f(x)\\) is evaluation.\nI thought that the function can be represented by the inner product of the basis of feature space \\(K(\\cdot,x)\\) and coefficients \\(f\\), and the coefficients are vectors in feature space.\nThe reproducing property of Kernel is \\(\\langle f, K(\\cdot,x)\\rangle_{\\mathcal{H}} = f(x)\\). Thus \\(K(\\cdot,x) \\in \\mathcal{H}_K\\). \\(K(\\cdot,x)\\) is a \\(x\\) specified function in Hilbert space \\(\\mathcal{H}_K\\) and an evaluator of the specific point x. This means the inner product of \\(f\\) and \\(K_{x}\\) is the value of \\(f\\) at point \\(x\\), \\(f(x)\\).\nIn a nutshell, kenel method is a different way of evaluating f in a specific point \\(x\\). Evaluating a function \\(f\\) at a point \\(x\\) is inner product of \\(f\\) and \\(L_x\\), where \\(L_x \\in \\mathcal{H}_K\\) is a evaluation functional which is a kernal function and linear \\(K(\\cdot, x)\\). Reproducing property of \\(\\mathcal{H}_K\\) can be achieved if all \\(f \\in \\mathcal{H}\\) has bounded evaluation functionals (\\(L_x\\)).\nIn least square methods, the parameters (\\(\\hat{\\beta}\\)) are determined by inner product of \\(X\\) \\(\\hat{\\beta} = (X^{T}X)^{-1}X^{T}y\\). In Kernel method, \\(\\hat{\\beta}\\) is determined \\(\\langle K(\\cdot,x_i), K(\\cdot,x_j), \\rangle_{\\mathcal{H}_K} = K(x_i, x_j)\\). Each \\(K(\\cdot, x)\\) is a parameter and a argument (variable like \\(x\\)).\nSome subclass of the loss function and penalty functions can be generated by a positive definite kernel. A Kernel accepts two arguments and a Kernel function does one argument and the other argument becomes parameter. Reproducing Kernel Hilbert space is a function space with Kernal function space with the evaluation functional as a Kernel. The feature expansion into the RKHS can use the Kernel matrix instead of the inner product of each variable \\(X^TX\\).\nThe important concepts are Hilbert space, inner product, Kernel function, evaluation functional, feature expansion, Fourier transformation, Reisz representation theorem (dual space \\(\\mathcal{H}_{K}^*\\) of Hibert space \\(\\mathcal{H}_K\\))\n","date":1576800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576834061,"objectID":"ca5677bc8a823ad60f5523f87db7af0d","permalink":"/post/reproducing-kernel-hilbert-space/","publishdate":"2019-12-20T00:00:00Z","relpermalink":"/post/reproducing-kernel-hilbert-space/","section":"post","summary":"Finally arrive at reproducing kernel Hilbert space. https://nzer0.github.io/reproducing-kernel-hilbert-space.html\nThe above post introduces RKHS in Korean. It was helpful. I had struggled to understand some concepts in RKHS. What does mean Hilbert space in terms of feature expansion? (\\(f:\\mathcal{X} \\to \\mathbb{R}\\), \\(f \\in \\mathcal{H}_K\\)) It was confusing the difference between \\(f\\) and \\(f(x)\\). \\(f\\) means the function in Hilbert space and \\(f(x)\\) is evaluation.\nI thought that the function can be represented by the inner product of the basis of feature space \\(K(\\cdot,x)\\) and coefficients \\(f\\), and the coefficients are vectors in feature space.","tags":["Machine learning","Math","Reproducing kernel hilbert space"],"title":"Reproducing Kernel Hilbert Space","type":"post"},{"authors":[],"categories":["Pathology"],"content":" Dr. Dina R. Mody HPV test  DNA HPV test will fail. BD (Oncolarity) is for a screening test. genotype 66 high risk. False-negative 10%. DNA copy number is the cause. False positive cross reactivity 0.35%, 0.71% Aptima and Cobas. (one quarter)  Dr. Sneige Immunostain in breast  Reduced and diminished myoepithelial cells, phenotypic alteration, SMA remain but others lost. Any positivity for MEC favors in situ than invasive. Metaplastic carcinoma and fibromatosis like TTF-1 2% positive in breast cancer.  Dr. Prieto Cutaneous lymphoma  Mycosis fungoides cell are atypical 7 fold folding nuclear membrane CD4 predominant than CD8 Mycosis fungoides with large cell transformation CD8 mycosis fungoides Granulomatous MF Immunohistochemistry marker related to TX  CD25, CD30   Again Dr. Mody  Super D specimen preparation Guideline will be released.  Dr. Medeiros, Hodgkin lymphomas  Popcorn, not poped Hodgkin lymphoma cells were renamed. LP cells, Lacunar cells, RS + mononuclear variants/anaplastic variants  Dr. El-Naggar H\u0026amp;N cancer  HPV nasopharyngeal carcinoma Young caucasian male H\u0026amp;N is different from anogenital area  Dr. Moran  Neuroendocrine carcinoma in lung Do not follow the WHO without own justification Mitoses count is not rigorous measurement. eyepiece diameters, hotspot vs random Arrigoni criteria 1974 was 5-10 mitosis per 10 HPF  Dr. Jihun Kim colitis  Yersinia\n Suppurative granulomas Heaped up mass-like mucosal thickening Superficial ileocecal lesion Lymphoid follicles\n  NSAID-induced enteropathy\n Radiating fibrosis around the ulcer Diaphragm-like stricture  Nivolumab-induced colitis\n  Dr. Moran Salivary-gland type tumors of the lung  Central intrabronchial mass Frozen diagnosis important sleeve or total pneumonectomy Adenosquamous is different with mucoepidermoid Mucoepidermoid m/c and children MAML2 translocation Acinic cell carcinoma gold standard is EM  Dr. Sneige Breast cancer biomarkers  ER test SP1 Scandle https://www.cbc.ca/news/canada/newfoundland-labrador/lab-mistakes-poor-oversight-flagged-in-n-l-breast-cancer-inquiry-1.793504 Fixation time 6hr - 72 hr False negative Control tissues HER2 test 2018 guidelines OncotypeDX NEJM 2018 intermediated group can skip chemotherapy  Dr. Prieto Cutaneous mesenchymal tumors  Dermatofibroma vs Dermatofibrosarcoma protuberance Epithelioid fibrous histiocytoma  Resembling melanoma  Angiomatoid fibrous histiocytoma  Translocation EWSR1, FUS, CREB1, ATF1  Atypical fibroxanthoma  Solitary lesion on sun-exposed skin Elderly adult  Neurothekeoma  Dr. Medeiros Marginal zone lymphomas  There category vs two cathegory (feat Dr. In-sun Kim) Colonization in follicles Cause of disease infection  H. pylori HCV Campylobacter jejuni  Boring immunophenotype, important translocations  API2 and MALT1 IGH and MALT1 FOXP1 and MALT1 BCL10 and IGH  Large cell transformaion Splenic marginal zone lymphoma  Systemic involvement, bone marrow, peripheral blood   Dr. El-Naggar  Salivary gland tumor  Ductal carcinoma Homology with breast, prostate Testosterone, Androgen, and Steroid Androgen receptor, Glucocorticoid receptor Androgen receptor splicing variant: constitutive activation   Dr. Kyu-Rae Kim  Progestin treatment failure  Myometrial invasion, basal layer involvement  No guideline for residual tumor  ","date":1575590400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575608365,"objectID":"d2aed31b75823bff29a2dac942babdc7","permalink":"/post/asan-surgical-pathology-update/","publishdate":"2019-12-06T00:00:00Z","relpermalink":"/post/asan-surgical-pathology-update/","section":"post","summary":"Dr. Dina R. Mody HPV test  DNA HPV test will fail. BD (Oncolarity) is for a screening test. genotype 66 high risk. False-negative 10%. DNA copy number is the cause. False positive cross reactivity 0.35%, 0.71% Aptima and Cobas. (one quarter)  Dr. Sneige Immunostain in breast  Reduced and diminished myoepithelial cells, phenotypic alteration, SMA remain but others lost. Any positivity for MEC favors in situ than invasive.","tags":[],"title":"Asan surgical pathology update","type":"post"},{"authors":[],"categories":["Cancer","cbioportal","R"],"content":" https://github.com/Jkang-alien/ion2cbioportal\nThis is Rpackage for making the cbioportal dataset from the ion torrent NGS result files. The formats of ion torrent result files are vcf and tsv. Those files convert to maf format and other data set for cbioportal. The package includes vignette. vignette(\u0026quot;ion2cbioportal\u0026quot;)\n","date":1575331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575358677,"objectID":"c2e2927e4b2990681d884eecf468c790","permalink":"/post/ion2cbioportal-rpackage/","publishdate":"2019-12-03T00:00:00Z","relpermalink":"/post/ion2cbioportal-rpackage/","section":"post","summary":"https://github.com/Jkang-alien/ion2cbioportal\nThis is Rpackage for making the cbioportal dataset from the ion torrent NGS result files. The formats of ion torrent result files are vcf and tsv. Those files convert to maf format and other data set for cbioportal. The package includes vignette. vignette(\u0026quot;ion2cbioportal\u0026quot;)","tags":["cbioportal","R","Ion Torrent","Thermo fisher Scientific"],"title":"ion2cbioportal Rpackage","type":"post"},{"authors":[],"categories":["Math"],"content":" Here I summarize some tools for proof of the Riesz representation theorem. They are the limit of inequality of sequence and \\(\\epsilon\\). The Rudin’s proof of the Riesz representation theorem construct measure \\(\\mu\\) and measurable set \\(\\mathfrak{M}\\), then prove the \\(\\mu\\) and \\(\\mathfrak{M}\\) have properties. Countable additivity (not subadditivity) is an important property. The strategy of proving equality (additivity) is bidirectional inequality.\nLimit of inequality of sequence gives us a tool that finite inequality makes infinite inequality. \\(\\epsilon\\) changes left and right parts of inequality (bidirectional inequality).\nIf \\(\\Sigma^n_1\\mu(K) \\le \\Sigma^n_1\\mu(V_i)\\) then \\(\\Sigma^{\\infty}_1 \\mu(K) \\le \\Sigma^{\\infty}_1 \\mu(V)\\), K is compact and V is open. We can change both sides of inequality with \\(\\epsilon\\). \\(\\Sigma^{\\infty}_1 \\mu(V) \\le \\Sigma^{\\infty}_1 \\mu(K) + \\epsilon\\).\nUrison’s lemma is used for \\(\\mu(E) = \\inf\\mu(V) = \\sup\\mu(K)\\) if $ E $ and $ K E V$.\n","date":1573257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573248754,"objectID":"137e41271c5ade41bc9bea179f65eb2b","permalink":"/post/limit-of-inequality-and-epsilon/","publishdate":"2019-11-09T00:00:00Z","relpermalink":"/post/limit-of-inequality-and-epsilon/","section":"post","summary":"Here I summarize some tools for proof of the Riesz representation theorem. They are the limit of inequality of sequence and \\(\\epsilon\\). The Rudin’s proof of the Riesz representation theorem construct measure \\(\\mu\\) and measurable set \\(\\mathfrak{M}\\), then prove the \\(\\mu\\) and \\(\\mathfrak{M}\\) have properties. Countable additivity (not subadditivity) is an important property. The strategy of proving equality (additivity) is bidirectional inequality.\nLimit of inequality of sequence gives us a tool that finite inequality makes infinite inequality.","tags":["Analysis","Limit","Math"],"title":"Limit of inequality of sequence and epsilon","type":"post"},{"authors":[],"categories":["Math"],"content":" This is a note of real and complex analysis chapter 2.\nChapter 2 is about measures. The measure already defined in chapter 1. In chapter 2, every linear functionals, not combination, of a continuous function space on compact set (\\(C\\)) (\\(\\Lambda f\\)) represents the integration of the function (\\(\\int f du\\)) (Riesz representation theorem). Let X be a locally compact Hausdorf space, and let \\(\\Lambda\\) be a positive linear functional on \\(C_c(X)\\). Then there exist a \\(\\sigma-algebra\\) in \\(X\\) which contains all Borel sets in \\(X\\), and there exists a unique positive measure \\(mu\\) on \\(\\mathfrak{M}\\) which represents \\(\\Lambda\\) in the sense that (a) \\(\\Lambda f = \\int f d \\mu\\) for every \\(f \\in C_c(X)\\) and following additional properties:\n(b) \\(\\mu(K) \u0026lt; \\infty\\) for every compact set \\(K \\subset X\\).\n(c) For every \\(E \\in \\mathfrak{M}\\), we have \\[ \\mu(E) = inf\\{\\mu(V): E in V, V open\\} \\].\n(d) The relation \\[\\mu(E)=sup\\{\\mu(K): K \\in E, K compact\\}\\]\nholds for every open set \\(E\\), and for every \\(E \\in M\\) with \\(\\mu(E) \u0026lt; \\infty\\).\n(e) If \\(E \\in \\mathfrak{M}, A subset E\\), and \\(\\mu(E) = 0\\), then \\(A \\in \\mathfrak{M}\\).\nThe Riesz theorem is about linear functional \\(\\Lambda\\) is equivalently replaced with choosing measure \\(\\mu(E)=sup\\{\\Lambda f: f \\prec V\\}\\). Note \\(sup \\{\\int^1_0 f(x)dx = \\Lambda f: f \\prec V, V (0,1) \\} = 1\\). The notion of \\(\\prec\\) include \\(0 \\le f \\le 1\\).\nI confused \\(C_c(X)\\)\n","date":1571184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571211588,"objectID":"21a84bdf1250c0d9a375c756b6c59fdf","permalink":"/post/positive-borel-measures/","publishdate":"2019-10-16T00:00:00Z","relpermalink":"/post/positive-borel-measures/","section":"post","summary":"This is a note of real and complex analysis chapter 2.\nChapter 2 is about measures. The measure already defined in chapter 1. In chapter 2, every linear functionals, not combination, of a continuous function space on compact set (\\(C\\)) (\\(\\Lambda f\\)) represents the integration of the function (\\(\\int f du\\)) (Riesz representation theorem). Let X be a locally compact Hausdorf space, and let \\(\\Lambda\\) be a positive linear functional on \\(C_c(X)\\).","tags":["Analysis","Functional analysis","Math"],"title":"Positive Borel measures","type":"post"},{"authors":[],"categories":["Math"],"content":" This is a note for Rudin’s real and complex analysis chapter 1. The key concepts are \\(\\sigma\\)-algebra, measure (\\(\\mu\\)) zero, and linear combination. The three concepts bring me abstract integration. The \\(\\sigma\\)-algebra makes that countable sum and measure of complement (subtract measure) can be possible. Measure zero completes the system. linear combination integrates a measurable function.\nAfter a measure space established, Lebesgue’s monotone convergence theorem, Fatou’s lemma, and Lebesgue’s dominant convergence theorem follow. Although three theorems do not contain integral in their name, they insist that pointwise convergent sequence of functions is also converging their integral of the limit of functions. Lebesgue’s monotone convergence theorem requires a monotonous increment of series of functions and Lebesgue’s dominant convergence theorem requires upper bound function. Fatou’s lemma is the inequality of the lower limit.\nLebesgue’s monotone convergence theorem can be proved by the fact all \\(L_1(\\mu)\\) has convergent simple function sequence. \\(f_n\\) \u0026gt; simple functions holds inequality of \\(\\lim\\int f_n \\geq \\lim\\int S_n = \\int f\\). Fatous’s lemma \\(\\lim \\inf \\int \\lvert fn - f \\rvert \\leq\\int \\lim \\inf \\lvert f_n - f \\rvert\\) is used for proof of Lebesgue’s dominant convergence.\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570572875,"objectID":"90d4305810956c2779cbb40a84846a36","permalink":"/post/abstract-integration/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/post/abstract-integration/","section":"post","summary":"This is a note for Rudin’s real and complex analysis chapter 1. The key concepts are \\(\\sigma\\)-algebra, measure (\\(\\mu\\)) zero, and linear combination. The three concepts bring me abstract integration. The \\(\\sigma\\)-algebra makes that countable sum and measure of complement (subtract measure) can be possible. Measure zero completes the system. linear combination integrates a measurable function.\nAfter a measure space established, Lebesgue’s monotone convergence theorem, Fatou’s lemma, and Lebesgue’s dominant convergence theorem follow.","tags":["Analysis","Math"],"title":"Abstract integration","type":"post"},{"authors":[],"categories":["Genomics"],"content":"\n\n\n\n","date":1569542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569551527,"objectID":"5eb3eae472bbd62cf27a0e61f34a6324","permalink":"/talk/allele-frequency-and-somatic-variant/","publishdate":"2019-09-27T00:00:00Z","relpermalink":"/talk/allele-frequency-and-somatic-variant/","section":"talk","summary":"","tags":["Cancer","Genomics","NGS","Pathology"],"title":"Allele frequency and somatic variant","type":"talk"},{"authors":[],"categories":["Genomics"],"content":" Molecular tumor board 2019/09/26\nKCSG GY Cancer Symposium, Dragon city hotel, 2019/11/08\n","date":1568764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568875266,"objectID":"3a2e4ee44ca8fb37054ae28ac9e65d48","permalink":"/talk/acmg-standards-and-guidelines-for-interpretation-of-sequence-variants/","publishdate":"2019-09-18T00:00:00Z","relpermalink":"/talk/acmg-standards-and-guidelines-for-interpretation-of-sequence-variants/","section":"talk","summary":"Molecular tumor board 2019/09/26\nKCSG GY Cancer Symposium, Dragon city hotel, 2019/11/08","tags":["Cancer","Genomics"],"title":"ACMG Standards and guidelines for interpretation of sequence variants","type":"talk"},{"authors":[],"categories":["Cancer","Genomics"],"content":" The 71st Annual Fall Meeting of Korean Society of Pathologists Case presentation at molecular pathology lecture\n","date":1568073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568083623,"objectID":"41394b8946117beddf382dded22934ef","permalink":"/talk/annotation-redundancy/","publishdate":"2019-09-10T00:00:00Z","relpermalink":"/talk/annotation-redundancy/","section":"talk","summary":"The 71st Annual Fall Meeting of Korean Society of Pathologists Case presentation at molecular pathology lecture","tags":["Cancer","Genomics","NGS","Pathology"],"title":"Annotation Redundancy","type":"talk"},{"authors":[],"categories":["R","Machine learning"],"content":"\n\n\n\n","date":1568073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568080707,"objectID":"45dd797898005bd557cb36de87b9af03","permalink":"/talk/predictive-modeling/","publishdate":"2019-09-10T00:00:00Z","relpermalink":"/talk/predictive-modeling/","section":"talk","summary":"","tags":["R","Machine learning"],"title":"Predictive Modeling","type":"talk"},{"authors":[],"categories":["Math"],"content":" The compact is a property of space. In a nutshell, if space is compact, we can treat the space be a finite because space has a finite subcover. A continuous function on a compact space is uniformly continuous.\nHeine-Borel theorem describes the condition of compactness of finite dimensional space. Closed and bounded But the Heine-Borel theorem does not hold in an infinite-dimensional space. We need another condition.\nPreviously, the compact space can be finite by taking subcover. The infinite-dimensional space can be finite by projection to finite dimension. If we could make as small as possible (i.e. \\(\\epsilon \u0026gt; 0\\) ) the norm of \\((X\\backslash(1-P)\\), the compactness is achieved.\n","date":1567814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567811967,"objectID":"9b5b46a9e935da5fe656e46c0916560c","permalink":"/post/math/compactness/","publishdate":"2019-09-07T00:00:00Z","relpermalink":"/post/math/compactness/","section":"post","summary":"The compact is a property of space. In a nutshell, if space is compact, we can treat the space be a finite because space has a finite subcover. A continuous function on a compact space is uniformly continuous.\nHeine-Borel theorem describes the condition of compactness of finite dimensional space. Closed and bounded But the Heine-Borel theorem does not hold in an infinite-dimensional space. We need another condition.\nPreviously, the compact space can be finite by taking subcover.","tags":["Analysis","Compactness","Math"],"title":"Compactness","type":"post"},{"authors":[],"categories":["Math"],"content":" Differential equation solution is infinite function series. The infinite function series can be a sort of linear combination of countable function vector, in terms of linear algebra. This raises the problem of the analysis of function. The problem includes a distance of two functions, ie norm, completeness (Banach space). Because the series adds the last term without changing the existing terms, orthogonality is required to make a linear combination of countable functional vector becomes infinite function series (Hilbert space).\nTo make a space of continous function on a compact interval \\(C(I)\\) be complete (Banach space), take the maximum norm. To make a space of \\(C(I)\\) orthogonal, take the norm associated with inner product \\(\\| f \\| := \\sqrt{ \\langle f,f \\rangle}\\). The inner product is a map of symmetric sesquilinear form (Hermitian form). In \\(C(I)\\), the inner product is \\[ \\langle f,g \\rangle := \\int_{a}^{b} f^{*} (x)g(x)dx \\] But the \\(C(I)\\) with the norm associated with an inner product is not complete. The complete can be achieved by extension to the Lebesgue integrable function. The right norm and the right functional set have special properties like complete and orthogonality.\n","date":1567123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567157967,"objectID":"61fb3903991a4fc903475901bbdcf27d","permalink":"/post/math/functional-analysis/","publishdate":"2019-08-30T00:00:00Z","relpermalink":"/post/math/functional-analysis/","section":"post","summary":"Differential equation solution is infinite function series. The infinite function series can be a sort of linear combination of countable function vector, in terms of linear algebra. This raises the problem of the analysis of function. The problem includes a distance of two functions, ie norm, completeness (Banach space). Because the series adds the last term without changing the existing terms, orthogonality is required to make a linear combination of countable functional vector becomes infinite function series (Hilbert space).","tags":["Analysis","Functional analysis"],"title":"Functional analysis","type":"post"},{"authors":[],"categories":["Math"],"content":" A sequence can be defined as a function on the domain of natural number like \\(1, 1/2, 1/3 ... 1/n\\). This sequence approach to the 0, but never touch the 0. However, people can not take their desire to link the sequence and the 0. Because \\(\\infty\\) is not a member of the natural number even real number, another concept is necessary to link the sequence and the 0. It is the limit. \\[ \\lim{n\\to\\infty} \\]\nThe above sequence approach to the 0. But does all sequences approach to some points? What if the sequence is \\(1/n\\) if \\(n\\) is not multiple of 100, 0.001 if n is multiple of 100.\nIts approach to zero except at every multiple of 10. The \\(\\epsilon\\) is used for the definition of limit to exclude this example.\nThe sequence \\(S\\) is converges the limit \\(a\\) if for every positive \\(\\epsilon\\), natural number \\(N\\) is present such that \\(\\vert a-Sn \\vert \u0026lt;\\epsilon\\) is true in every \\(n\u0026gt;N\\). Otherwise, the limit is not defined and the sequence is divergent.\nIn topological space, the \\(\\epsilon\\) becomes the neighborhood.\n","date":1566259200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566467688,"objectID":"6da4e3f52b41864bd076753c1837d6a0","permalink":"/post/math/limit/","publishdate":"2019-08-20T00:00:00Z","relpermalink":"/post/math/limit/","section":"post","summary":"A sequence can be defined as a function on the domain of natural number like \\(1, 1/2, 1/3 ... 1/n\\). This sequence approach to the 0, but never touch the 0. However, people can not take their desire to link the sequence and the 0. Because \\(\\infty\\) is not a member of the natural number even real number, another concept is necessary to link the sequence and the 0. It is the limit.","tags":["Analysis","Limit","Math"],"title":"Limit","type":"post"},{"authors":[],"categories":["R"],"content":" An NGS pathology report contains an interpretation section to describe the clinical interpretation of the found genomic variants of the patient’s cancer sample. The interpretation is different from each variant and each cancer type or the other clinical factors. The pathologists describe the interpretation and archive those in certain methods including tables like excel.\nI make a shinyapp to archive the interpretations to a database and search them.\nhttps://jkang.shinyapps.io/Interpretation/\n","date":1565481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565511835,"objectID":"aab39c41b08a82a92a4f24df702519d9","permalink":"/post/r/ngs-interpretation-database-and-search/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/post/r/ngs-interpretation-database-and-search/","section":"post","summary":"An NGS pathology report contains an interpretation section to describe the clinical interpretation of the found genomic variants of the patient’s cancer sample. The interpretation is different from each variant and each cancer type or the other clinical factors. The pathologists describe the interpretation and archive those in certain methods including tables like excel.\nI make a shinyapp to archive the interpretations to a database and search them.\nhttps://jkang.shinyapps.io/Interpretation/","tags":["NGS","R","Shiny","Pathology","sqlite","shinyapps.io"],"title":"NGS interpretation database and search","type":"post"},{"authors":[],"categories":["Math"],"content":" The studying sometimes starts with learning of boring preceding concepts. The highlight comes later. In history, the highlight concepts or the important problem were centered and the supporting concepts or lemmas followed. One of the central ideas of analysis is extension. The set of a rational number (\\(\\mathbb{Q}\\)) extends to the real line \\(\\mathbb{R}\\). The Jordan measurable sets extend to the Lebesgue measurable sets ( \\(\\sigma -algebra\\) ).\nThe outer measure can measure all subsets of \\(X\\), whereas measure can only measure a \\(\\sigma -algebra\\) of measure set. The Carathéodory measurability defines the condition to make a \\(\\sigma -algebra\\).\n\\[ \\mu^*(A) = \\mu^*(A \\cap E) + \\mu^*(A \\cap E^c) \\] The Carathéodory extension theorem defines a condition to make an outer measure to a measure. The condition is that the outer measure applies to the Carathéodory measurable set (\\(\\sigma - algebra\\)). (Torrence Tao, An introduction to measure theory)\nIn the Riesz representation therorem, \\(\\mathfrak{M}_F\\) extends to \\(\\mathfrak{M}\\). The outer measure is \\(\\mu(E) = sup\\ \\ \\{\\mu(K): K \\subset E,\\ \\ K \\ \\ compact \\}\\) for every \\(E \\subset X\\) analogus to Jordan outer measure. \\(\\mathfrak{M}_F\\) is collection of subset \\(E \\subset X\\) satisfying \\(\\mu (E) \u0026lt; \\infty\\) and \\(\\mu (V) = sup \\{\\Lambda f:f\\prec V \\}\\) analogus to Jordan inner measure. Thus \\(\\mathfrak{M}_F\\) is analous to Jordan measurable set. \\(\\mathfrak{M}\\) is collection of subset \\(E \\subset X\\) such that \\(E \\cap K \\ \\in \\ \\ \\mathfrak{M}_F\\) for every compact \\(K\\). This is the Carathéodory measurability. So the \\(\\mu(E)\\) on the \\(\\mathfrak{M}\\) becomes measure. (Rudin’s Real and complex analysis)\n","date":1565136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565149684,"objectID":"e0a0367c276f97367c574a074098d60e","permalink":"/post/math/caratheodory-s-extension-theorem/","publishdate":"2019-08-07T00:00:00Z","relpermalink":"/post/math/caratheodory-s-extension-theorem/","section":"post","summary":"The studying sometimes starts with learning of boring preceding concepts. The highlight comes later. In history, the highlight concepts or the important problem were centered and the supporting concepts or lemmas followed. One of the central ideas of analysis is extension. The set of a rational number (\\(\\mathbb{Q}\\)) extends to the real line \\(\\mathbb{R}\\). The Jordan measurable sets extend to the Lebesgue measurable sets ( \\(\\sigma -algebra\\) ).\nThe outer measure can measure all subsets of \\(X\\), whereas measure can only measure a \\(\\sigma -algebra\\) of measure set.","tags":["Analysis","Math","Compactness","Functional analysis"],"title":"Carathéodory's extension theorem","type":"post"},{"authors":null,"categories":["Math"],"content":" The reproducing kernel hilbert space (RKHS) was my motivation to study analysis. The hilbert space is a orthogonal normed vector space. I still do not know about the meaning of “reproducing kernal”. The RKHS appeared in the book titled An Introduction to Statisitical Learning written by Hastie.\nI began to google the meaning of the spaces such as the Hilbert, Banarch. I decided to read the Understaing Analysis written by Abbott. The Understaing Analysis was give me many intuitions of analysis and encouraged me to study further. The next book was Rudin’s Functional Analysis. I realized I need to go upstream to complex Analysis, topology and measure.\nDuring the journey of exploring the analysis, I skipped proving of theorems or solving exercises. But space between lines is coming. I’m realizing that I prove the spaces. \\[\\Sigma^{k}_{j=1} {\\lvert}a_j-a^{n}_j{\\rvert}\\le\\epsilon \\] This holds for all finite \\(k\\), we even have \\({\\lVert} a-a_n {\\rVert} _{1}\\le\\epsilon\\). This is on the way of the proof of \\(l^{1}(\\mathbb{N})\\) of all complex-valued sequences \\(a=(a_j)^{\\infty}_{j=1}\\) for which the norm \\({\\lVert} a {\\rVert} _{1}\\ := \\Sigma^{\\infty}_{j=1} {\\lvert}a_j{\\rvert}\\).\nI could not just accept that the finite sum of each small differences \\(\\le \\epsilon\\) of \\({\\lvert}a_j - a^n_j{\\rvert}\\) holds to the infinite sum. The infinite sum is a infinte series. If the infinite series is less than or equel to zero, then it converses to the zero. If the finite sum is \\(\\le \\epsilon\\) holds every \\(\\mathbb{N}\\), by definition the infinite sum is also \\(\\le \\epsilon\\).\nIt takes long time to grasp the subtle mathmatical systems. For example, a series is a number in a scalar field, a sequence is a ordered set. However the long time makes the math become familar and finally will firmly grasp the subtle concepts.\n","date":1564704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564704000,"objectID":"54b43170d69e1ac786947fb280bd45b5","permalink":"/post/math/analysis/","publishdate":"2019-08-02T00:00:00Z","relpermalink":"/post/math/analysis/","section":"post","summary":"The reproducing kernel hilbert space (RKHS) was my motivation to study analysis. The hilbert space is a orthogonal normed vector space. I still do not know about the meaning of “reproducing kernal”. The RKHS appeared in the book titled An Introduction to Statisitical Learning written by Hastie.\nI began to google the meaning of the spaces such as the Hilbert, Banarch. I decided to read the Understaing Analysis written by Abbott.","tags":["Analysis","Limit","Reproducing kernel hilbert space"],"title":"Analysis","type":"post"},{"authors":[],"categories":["Cancer","Genomics","TCGA"],"content":"Abstact\nTCGA is a large consortium of comprehensive cancer genomic research that opens publically the data. There are several way to access to the TCGA data. This talk introduce among the simple ways.\n","date":1558656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564807111,"objectID":"bafdffc74c64f048dd2bbbda0a3926fe","permalink":"/talk/big_data/big-data-tcga/","publishdate":"2019-05-24T00:00:00Z","relpermalink":"/talk/big_data/big-data-tcga/","section":"talk","summary":"Abstact\nTCGA is a large consortium of comprehensive cancer genomic research that opens publically the data. There are several way to access to the TCGA data. This talk introduce among the simple ways.","tags":["TCGA","Cancer","Genomics","Big data","R","cbioportal","bioconductor"],"title":"Big Data TCGA ","type":"talk"},{"authors":[],"categories":["Stastics"],"content":" Abstract\nIntroduction of Bayesian approch in base calling and copy number variation (CNV). This is for the intradepartment lecture.\nurl_slides: ‘http://rpubs.com/JKang/492555’\n","date":1555718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564723321,"objectID":"7758b1d3b1b403e76e584278fb0cf9d2","permalink":"/talk/bayes_and_ngs/","publishdate":"2019-04-20T00:00:00Z","relpermalink":"/talk/bayes_and_ngs/","section":"talk","summary":"Abstract\nIntroduction of Bayesian approch in base calling and copy number variation (CNV). This is for the intradepartment lecture.\nurl_slides: ‘http://rpubs.com/JKang/492555’","tags":["Bayesian","NGS","R","Stan","Rstan"],"title":"Bayesian","type":"talk"},{"authors":["Ye Sul Jeong","Jun Kang","Jieun Lee","Tae-Kyung Yoo","Sung Hun Kim","Ahwon Lee"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2dc1c32c1cd5eb8564631a6733a4ccd9","permalink":"/publication/2019-01-01_jeonganalysismolecularsubtypes2019/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019-01-01_jeonganalysismolecularsubtypes2019/","section":"publication","summary":"","tags":[],"title":"Analysis of the Molecular Subtypes of Preoperative Core Needle Biopsy and Surgical Specimens in Invasive Breast Cancer","type":"publication"},{"authors":["Ahwon Lee","Jun Kang","Hyoungnam Lee","Youn Soo Lee","Youn Jin Choi","Keun Ho Lee","Goutam J Nistala","Charles R. Scafe","Jongpill Choi","Jaeeun Yoo","Eunhee {Han M.D}","Yonggoo Kim","Myungshin Kim"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"15cee90cbce2a000cfaee11667b09f8c","permalink":"/publication/2019-01-01_leebrca1somaticmutation2019/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019-01-01_leebrca1somaticmutation2019/","section":"publication","summary":"Introduction The detection of BRCA1/2 mutations is important because PARP1 inhibitors are approved for germline and/or somatic BRCA-mutated advanced ovarian cancer. Next-generation sequencing (NGS) is increasingly used in clinical practice for BRCA1/2 mutations. The purpose of this study was to consider several conditions of NGS BRCA1/2 assay applicable to clinical laboratory tests, in particular for using formalin fixed paraffin embedded (FFPE) ovarian tissues. Materials and methods We selected 64 ovarian cancer patients and performed Oncomine\\texttrademark BRCA assay using FFPE tissue. Effect of FFPE sample quality was analyzed by NGS quality parameters including deamination metric. Somatic variants were selected by removing germline variants of peripheral blood and interpreted as pathogenic, variants of unknown significance, and false positive. Results We found a positive relationship between the number of variants over the deamination metric and FFPE age (P $","tags":[],"title":"BRCA1/2 Somatic Mutation Detection in Formalin-Fixed Paraffin Embedded Tissue by next-Generation Sequencing in Korean Ovarian Cancer Patients","type":"publication"},{"authors":["Dongmin Kim","Jieun Lee","Jun Kang","Sung Hun Kim","Tae-Kyung Yoo","Sooeun Oh","Ahwon Lee"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"1c9aaa042609248220e0f89bcb001bcb","permalink":"/publication/2019-01-01_kimnotch1tumormicrovascular2019/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019-01-01_kimnotch1tumormicrovascular2019/","section":"publication","summary":"Kim D, et al. J Breast Cancer. 2019 Dec;22(4):562-578. https://doi.org/10.4048/jbc.2019.22.e56","tags":[],"title":"Notch1 in Tumor Microvascular Endothelial Cells and Tumoral miR-34a as Prognostic Markers in Locally Advanced Triple-Negative Breast Cancer","type":"publication"},{"authors":["So Won Lee","Hyunjin Park","Ho Yun Lee","Insuk Sohn","Seung-Hak Lee","Jun Kang","Jong-Mu Sun","Myung-Ju Ahn"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"d080afbf3d75b0c2819237e49d5e194c","permalink":"/publication/2018-01-01_lee2018deciphering/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-01-01_lee2018deciphering/","section":"publication","summary":"","tags":[],"title":"Deciphering Clinicoradiologic Phenotype for Thymidylate Synthase Expression Status in Patients with Advanced Lung Adenocarcinoma Using a Radiomics Approach","type":"publication"},{"authors":["Min-Wook Kim","Dae-Hyun Jang","Jun Kang","Seungok Lee","Sun Young Joo","Ja-Hyun Jang","Eun-Hae Cho","Young-Chul Choi","Jung Hwan Lee"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"6c492adff8224b586f71b529b19021bb","permalink":"/publication/2017-01-01_kim2017novel/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2017-01-01_kim2017novel/","section":"publication","summary":"","tags":[],"title":"Novel Mutation (c. 8725T$\u003e$ C) in Two Siblings With Late-Onset LAMA2-Related Muscular Dystrophy","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Si-Hyun Kim","Ik Hyun Jo","Jun Kang","Sun Young Joo","Jung-Hyun Choi"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"0f85871c66e44aced302a750d61194b3","permalink":"/publication/2016-01-01_kim2016dermatophyte/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/2016-01-01_kim2016dermatophyte/","section":"publication","summary":"","tags":[],"title":"Dermatophyte Abscesses Caused by Trichophyton Rubrum in a Patient without Pre-Existing Superficial Dermatophytosis: A Case Report","type":"publication"},{"authors":["Min Jee Kwak","Sun Ki Kim","Ki Jun Kim","Bum-Sik Lee","Jun Kang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"e7733861d8c333d64f22d8d64ad57328","permalink":"/publication/2016-01-01_kwak2016displaced/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/2016-01-01_kwak2016displaced/","section":"publication","summary":"","tags":[],"title":"Displaced Double-Layered Lateral Meniscus That Mimicked the Bucket-Handle Tear: A Case Report","type":"publication"},{"authors":["So Hee Song","Joong Hyun Ahn","Ho Yun Lee","Geewon Lee","Joon Young Choi","Jun Kang","Eun Young Kim","Joungho Han","O Jung Kwon","Kyung Soo Lee","{others}"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"2fecc5c58012b285203a474b0362eed2","permalink":"/publication/2016-01-01_song2016prognostic/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/2016-01-01_song2016prognostic/","section":"publication","summary":"","tags":[],"title":"Prognostic Impact of Nomogram Based on Whole Tumour Size, Tumour Disappearance Ratio on CT and SUVmax on PET in Lung Adenocarcinoma","type":"publication"},{"authors":["Jun Kang","Hee Jin Lee","Sun-Young Jun","Eun Su Park","Lee-so Maeng"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"5fb9ecb6c80a6f8be234dfdf583305da","permalink":"/publication/2015-01-01_kang2015cancer/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/publication/2015-01-01_kang2015cancer/","section":"publication","summary":"","tags":[],"title":"Cancer-Testis Antigen Expression in Serous Endometrial Cancer with Loss of X Chromosome Inactivation","type":"publication"},{"authors":["Sun-Young Jun","Eun Su Park","Jiyoung Kim","Jun Kang","Jae Jun Lee","Yoonjin Bae","Sang-Il Kim","Lee-So Maeng"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"651006990c44671a5fbb8f1303233c79","permalink":"/publication/2015-01-01_jun2015comparison/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/publication/2015-01-01_jun2015comparison/","section":"publication","summary":"","tags":[],"title":"Comparison of the Cobas 4800 HPV and HPV 9G DNA Chip Tests for Detection of High-Risk Human Papillomavirus in Cervical Specimens of Women with Consecutive Positive HPV Tests but Negative Pap Smears","type":"publication"},{"authors":["Jun Kang","Hee Jin Lee","Jiyoung Kim","Jae Jun Lee","Lee-so Maeng"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"43d8914451ec564bb48d242d453651ca","permalink":"/publication/2015-01-01_kang2015dysregulation/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/publication/2015-01-01_kang2015dysregulation/","section":"publication","summary":"","tags":[],"title":"Dysregulation of X Chromosome Inactivation in High Grade Ovarian Serous Adenocarcinoma","type":"publication"},{"authors":["Hee Jin Lee","Jeong-Ju Lee","In Hye Song","In Ah Park","Jun Kang","Jong Han Yu","Jin-Hee Ahn","Gyungyub Gong"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"329213b37af6e48a679117e096a301fb","permalink":"/publication/2015-01-01_lee2015prognostic/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/publication/2015-01-01_lee2015prognostic/","section":"publication","summary":"","tags":[],"title":"Prognostic and Predictive Value of NanoString-Based Immune-Related Gene Signatures in a Neoadjuvant Setting of Triple-Negative Breast Cancer: Relationship to Tumor-Infiltrating Lymphocytes","type":"publication"},{"authors":["Suh Eun Bae","Hwoon-Yong Jung","June Kang","Young Soo Park","Seunghee Baek","Ji-Hoon Jung","Ji Young Choi","Mi-Young Kim","Ji Yong Ahn","Kwi-Sook Choi","{others}"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"921c0157e9e0bec8d9912f0c5b771889","permalink":"/publication/2014-01-01_bae2014effect/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-01-01_bae2014effect/","section":"publication","summary":"","tags":[],"title":"Effect of Helicobacter Pylori Eradication on Metachronous Recurrence after Endoscopic Resection of Gastric Neoplasm","type":"publication"},{"authors":["Su-Jin Shin","Gyungyub Gong","Hee Jin Lee","Jun Kang","Young Kyung Bae","Ahwon Lee","Eun Yoon Cho","Ji Shin Lee","Kwang-Sun Suh","Dong Wha Lee","{others}"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"6ebb74ff842de1107794916422e3ad55","permalink":"/publication/2014-01-01_shin2014positive/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-01-01_shin2014positive/","section":"publication","summary":"","tags":[],"title":"Positive Expression of Insulin-like Growth Factor-1 Receptor Is Associated with a Positive Hormone Receptor Status and a Favorable Prognosis in Breast Cancer","type":"publication"},{"authors":["Hee Jin Lee","Ho Yun Lee","Jeong Hee Lee","Hajeong Lee","Guhyun Kang","Joon Seon Song","Jun Kang","Ju Han Kim"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"945a0cd3f1d4ae4f51b08966d8802a71","permalink":"/publication/2014-01-01_lee2014prognostic/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-01-01_lee2014prognostic/","section":"publication","summary":"","tags":[],"title":"Prognostic Significance of Biallelic Loss of PTEN in Clear Cell Renal Cell Carcinoma","type":"publication"},{"authors":["Suh Eun Bae","Hwoon-Yong Jung","June Kang","Young Soo Park","Seunghee Baek","Ji-Hoon Jung","Ji Young Choi","Mi-Young Kim","Ji Yong Ahn","Kwi-Sook Choi","{others}"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"bee4cb6bb108faad7e2697206d71a129","permalink":"/publication/2014-01-01_bae2014response/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-01-01_bae2014response/","section":"publication","summary":"","tags":[],"title":"Response to Abdallah et Al.","type":"publication"},{"authors":["Hyoung Jo","Sang Hoon Jung","Jun Kang","Hye Bin Yim","Kui Dong Kang"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"7a36f15f15de9fa81bde3e84dc36bbfa","permalink":"/publication/2014-01-01_jo2014sulodexide/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-01-01_jo2014sulodexide/","section":"publication","summary":"","tags":[],"title":"Sulodexide Inhibits Retinal Neovascularization in a Mouse Model of Oxygen-Induced Retinopathy","type":"publication"},{"authors":["Suh Eun Bae","Hwoon-Yong Jung","June Kang","Young Soo Park","Seunghee Baek","Ji-Hoon Jung","Ji Young Choi","Mi-Young Kim","Ji Yong Ahn","Kwi-Sook Choi","{others}"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"cba793dc536b50b1c50b646ac87909f4","permalink":"/publication/2014-01-01_bae2014comes/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-01-01_bae2014comes/","section":"publication","summary":"","tags":[],"title":"When It Comes to Gastric Cancer, There Is More to It Than H-Pylori! Response","type":"publication"},{"authors":["Bong Chul Shin","Nae-Yun Heo","Mi-Seon Kang","Ju Won Lee","Seunghyun Park","Kyubok Jin","Jun Kang"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"f245190aee1416a9f0c96691e319a99c","permalink":"/publication/2013-01-01_shin2013case/","publishdate":"2013-01-01T00:00:00Z","relpermalink":"/publication/2013-01-01_shin2013case/","section":"publication","summary":"","tags":[],"title":"A Case of Henoch-Sch\\\"onlein Purpura Presenting with Cholestatic Hepatitis","type":"publication"},{"authors":["Young Kyung Bae","Gyungyub Gong","Jun Kang","Ahwon Lee","Eun Yoon Cho","Ji Shin Lee","Kwang-Sun Suh","Dong Wha Lee","Woo Hee Jung","Breast Pathology Study Group {of Korean Society of Pathologists}","{others}"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"2fef4602889e1c06f25363498e742ca0","permalink":"/publication/2012-01-01_bae2012her2/","publishdate":"2012-01-01T00:00:00Z","relpermalink":"/publication/2012-01-01_bae2012her2/","section":"publication","summary":"","tags":[],"title":"HER2 Status by Standardized Immunohistochemistry and Silver-Enhanced in Situ Hybridization in Korean Breast Cancer","type":"publication"},{"authors":["Young Kyung Bae","Gyungyub Gong","Jun Kang","Ahwon Lee","Eun Yoon Cho","Ji Shin Lee","Kwang-Sun Suh","Dong Wha Lee"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"65a4532abe0584f6aa197945ea4babbc","permalink":"/publication/2012-01-01_bae2012hormone/","publishdate":"2012-01-01T00:00:00Z","relpermalink":"/publication/2012-01-01_bae2012hormone/","section":"publication","summary":"","tags":[],"title":"Hormone Receptor Expression in Invasive Breast Cancer among Korean Women and Comparison of 3 Antiestrogen Receptor Antibodies: A Multi-Institutional Retrospective Study Using Tissue Microarrays","type":"publication"},{"authors":["Gi Cheol Park","Kyung-Ja Cho","Jun Kang","Jong-Lyel Roh","Seung-Ho Choi","Sang Yoon Kim","Soon Yuhl Nam"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"d79117ff268a22d7b0be06ca77b6f2bc","permalink":"/publication/2012-01-01_park2012relationship/","publishdate":"2012-01-01T00:00:00Z","relpermalink":"/publication/2012-01-01_park2012relationship/","section":"publication","summary":"","tags":[],"title":"Relationship between Histopathology of Pleomorphic Adenoma in the Parotid Gland and Recurrence after Superficial Parotidectomy","type":"publication"},{"authors":["Jeong-Ju Lee","Hee Jin Lee","Jun Kang","Jeong-Hyeon Jo","Gyungyub Gong"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"335fcb86b6f51e022dbb9ad3d02d6fd2","permalink":"/publication/2012-01-01_lee2012ratio/","publishdate":"2012-01-01T00:00:00Z","relpermalink":"/publication/2012-01-01_lee2012ratio/","section":"publication","summary":"","tags":[],"title":"The Ratio of Atypical Ductal Hyperplasia Foci to Core Numbers in Needle Biopsy: A Practical Index Predicting Breast Cancer in Subsequent Excision","type":"publication"},{"authors":["Young Wha Koh","Hee Jin Lee","Jong Won Lee","Jun Kang","Gyungyub Gong"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"b53c9218e765dd91c0c1e4ddd030bf08","permalink":"/publication/2011-01-01_koh2011dual/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/2011-01-01_koh2011dual/","section":"publication","summary":"","tags":[],"title":"Dual-Color Silver-Enhanced in Situ Hybridization for Assessing HER2 Gene Amplification in Breast Cancer","type":"publication"},{"authors":["Jun Kang","Jeong Hyun Cho","Cheol Won Suh","Dae Ho Lee","Heung Bum Oh","Yong Hak Sohn","Hyun Sook Chi","Chan Jeong Park","Sung Soo Jang","Kyoo Hyung Lee","{others}"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"cb5775a2c8a89964b9257d2e896f5335","permalink":"/publication/2011-01-01_kang2011high/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/2011-01-01_kang2011high/","section":"publication","summary":"","tags":[],"title":"High Prevalence of Hepatitis B and Hepatitis C Virus Infections in Korean Patients with Hematopoietic Malignancies","type":"publication"},{"authors":["Joo Young Kim","Hee Jin Lee","Jun Kang","Se Jin Jang"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"6b1edd5528a089c78d9046aa3817d0f7","permalink":"/publication/2011-01-01_kim2011histologic/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/2011-01-01_kim2011histologic/","section":"publication","summary":"","tags":[],"title":"Histologic Parameters Predicting Survival of Patients with Multiple Non-Small Cell Lung Cancers.","type":"publication"},{"authors":["Sukjoong Oh","Dong Hoe Koo","Cheolwon Suh","Shin Kim","Bong Hee Park","Joon Kang","Jooryung Huh"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"1c1d8ab8d7d11a7f3f0887c43f3d329c","permalink":"/publication/2011-01-01_oh2011prognostic/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/2011-01-01_oh2011prognostic/","section":"publication","summary":"","tags":[],"title":"Prognostic Value of Immunohistochemical Biomarkers at Different Cut-off Values in Patients with Diffuse Large B-Cell Lymphoma Treated with CHOP Chemotherapy","type":"publication"},{"authors":["Jun Kang","Dong-ho Shin","Jong-hyun Lee","Sunhee Bang","Dong-Il Kim"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"13994af1d48c8fe19a353064e1174196","permalink":"/publication/2010-01-01_kang2010rapid/","publishdate":"2010-01-01T00:00:00Z","relpermalink":"/publication/2010-01-01_kang2010rapid/","section":"publication","summary":"","tags":[],"title":"Rapid Increase in the Prevalence of Inflammatory Bowel Disease in Candidates for the Military Service Born after 1988 in Korea","type":"publication"},{"authors":["Jun Kang","Gui Young Kwon","Young-Hee Lee","Gyungyub Gong"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"5ed7c90479aae26c5841ff9652010e1d","permalink":"/publication/2009-01-01_kang2009comparison/","publishdate":"2009-01-01T00:00:00Z","relpermalink":"/publication/2009-01-01_kang2009comparison/","section":"publication","summary":"","tags":[],"title":"Comparison of Silver-Enhanced in Situ Hybridization and Fluorescence in Situ Hybridization for HER2 Gene Status in Breast Carcinomas","type":"publication"},{"authors":["So Yeon Kim","Hyun Kwon Ha","Sung Won Park","Jun Kang","Kyoung Won Kim","Seung Soo Lee","Seong Ho Park","Ah Young Kim"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"ec0a08eda3e8bd2b8349a6608d5788a9","permalink":"/publication/2009-01-01_kim2009gastrointestinal/","publishdate":"2009-01-01T00:00:00Z","relpermalink":"/publication/2009-01-01_kim2009gastrointestinal/","section":"publication","summary":"","tags":[],"title":"Gastrointestinal Metastasis from Primary Lung Cancer: CT Findings and Clinicopathologic Features","type":"publication"},{"authors":["Heejin Lee","Jun Kang","Kyung Mo Kim","Joo Young Jang","Se Jin Jang","Eunsil Yu"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"94f388bc64fed6ab889e9f23e00fdb90","permalink":"/publication/2009-01-01_lee2009clinicopathological/","publishdate":"2009-01-01T00:00:00Z","relpermalink":"/publication/2009-01-01_lee2009clinicopathological/","section":"publication","summary":"","tags":[],"title":"The Clinicopathological Parameters for Making the Differential Diagnosis of Neonatal Cholestasis","type":"publication"},{"authors":["Jun Kang","Sang Yoon Kim","Kyung-Ja Cho"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"249e88cd555d0e2eec5982cd2e468b19","permalink":"/publication/2008-01-01_kang2008lymphadenoma/","publishdate":"2008-01-01T00:00:00Z","relpermalink":"/publication/2008-01-01_kang2008lymphadenoma/","section":"publication","summary":"","tags":[],"title":"Lymphadenoma of the Salivary Gland: A Novel Classification Based on Immunohistochemical Comparison of Benign and Malignant Lymphoepithelial Neoplasms","type":"publication"},{"authors":["Heon-Ju Kwon","Jae Ho Byun","Jun Kang","Seong Ho Park","Moon-Gyu Lee"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"fd28fc4fff51e0b0947105c09dabec3c","permalink":"/publication/2008-01-01_kwon2008solitary/","publishdate":"2008-01-01T00:00:00Z","relpermalink":"/publication/2008-01-01_kwon2008solitary/","section":"publication","summary":"","tags":[],"title":"Solitary Fibrous Tumor of the Pancreas: Imaging Findings","type":"publication"},{"authors":["Jun Kang","Hye-Jeong Choi","Eunsil Yu","Ilseon Hwang","Young Min Kim","Hee Jeong Cha"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"851c94a3549bff709decb5715f991a25","permalink":"/publication/2007-01-01_kang2007case/","publishdate":"2007-01-01T00:00:00Z","relpermalink":"/publication/2007-01-01_kang2007case/","section":"publication","summary":"","tags":[],"title":"A Case Report of Fetal Telangiectatic Focal Nodular Hyperplasia","type":"publication"},{"authors":["Jun Kang","Shin Kwang Khang","Jene Choi","Jeong Won Kim","Eul-Ju Seo","Bu-kyu Lee","Eunsil Yu"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"e62971f836db058f73e74a3765475b31","permalink":"/publication/2007-01-01_kang2007intraneural/","publishdate":"2007-01-01T00:00:00Z","relpermalink":"/publication/2007-01-01_kang2007intraneural/","section":"publication","summary":"","tags":[],"title":"Intraneural Perineurioma in the Tongue","type":"publication"},{"authors":["Young Ok Hong","Jun Kang","Gyung Yub Gong","Jae Hee Suh","Young Min Kim","Hye Jeong Choi","Ae Kyung Jeong","Hee Jeong Cha"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"9eb3c59daa3f15eb4b926ced111bca4f","permalink":"/publication/2007-01-01_hong2007localized/","publishdate":"2007-01-01T00:00:00Z","relpermalink":"/publication/2007-01-01_hong2007localized/","section":"publication","summary":"","tags":[],"title":"Localized Polyarteritis Nodosa of the Breast with Mammary Duct Ectasia-a Case Report","type":"publication"},{"authors":["Jun Kang","Young Ok Hong","Geung Hwan Ahn","Young Min Kim","Hee Jeong Cha","Hye Jeong Choi"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"7f15c6ca58a9046f3a6591b32062edf9","permalink":"/publication/2007-01-01_kang2007nasal/","publishdate":"2007-01-01T00:00:00Z","relpermalink":"/publication/2007-01-01_kang2007nasal/","section":"publication","summary":"","tags":[],"title":"Nasal Chondromesenchymal Hamartoma: A Case Report.","type":"publication"},{"authors":["Seung-Ho Choi","Kyung-Ja Cho","Soon-Yuhl Nam","Sang-wook Lee","Joon Kang","Sang Yoon Kim"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"fb4bde852ad36835c4fb950093e75ddf","permalink":"/publication/2006-01-01_choi2006clinical/","publishdate":"2006-01-01T00:00:00Z","relpermalink":"/publication/2006-01-01_choi2006clinical/","section":"publication","summary":"","tags":[],"title":"Clinical Significance of $B$1 Integrin Expression as a Prediction Marker for Radiotherapy in Early Glottic Carcinoma","type":"publication"},{"authors":["Hae-Woong Lee","Seung-Seog Han","Jun Kang","Mi-Woo Lee","Jee-Ho Choi","Kee-Chan Moon","Jai-Kyoung Koh"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"e80e505d8458746b190c45fc9511a0db","permalink":"/publication/2006-01-01_lee2006multiple/","publishdate":"2006-01-01T00:00:00Z","relpermalink":"/publication/2006-01-01_lee2006multiple/","section":"publication","summary":"","tags":[],"title":"Multiple Mucinous and Lipomatous Variant of Eccrine Angiomatous Hamartoma Associated with Spindle Cell Hemangioma: A Novel Collision Tumor?","type":"publication"},{"authors":["Jun Kang","Inchul Lee"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"685f9e4e3295e7f54a23ce159dfbfbca","permalink":"/publication/2006-01-01_kang2006tuj1/","publishdate":"2006-01-01T00:00:00Z","relpermalink":"/publication/2006-01-01_kang2006tuj1/","section":"publication","summary":"","tags":[],"title":"TuJ1 (Class III $\\beta$-Tubulin) as Phenotypic Marker of Lymphatic and Venous Valves","type":"publication"}]