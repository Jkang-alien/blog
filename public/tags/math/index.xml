<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math | Jun&#39;s Blog</title>
    <link>/tags/math/</link>
      <atom:link href="/tags/math/index.xml" rel="self" type="application/rss+xml" />
    <description>Math</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 14 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Math</title>
      <link>/tags/math/</link>
    </image>
    
    <item>
      <title>Laplace transformation</title>
      <link>/post/laplace-transformation/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/post/laplace-transformation/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The Fourier series represents a periodic function as a descrete vectors. The Fourier transformation turns a time domain non-periodic function into a frequency domain continuous function. The Fourier series and transformation change a single time base &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; into infinite frequency basis &lt;span class=&#34;math inline&#34;&gt;\(e^{inx}\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(e^{iwx}\)&lt;/span&gt;. The function on infinite basis domain can be represented by a vector or a function of basis domain &lt;span class=&#34;math inline&#34;&gt;\(v_{n}\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(f(w)\)&lt;/span&gt;. This is a coefficients of Fourier series or Fourier transformation.&lt;/p&gt;
&lt;p&gt;The basis of Fourier transformation is pure frequency &lt;span class=&#34;math inline&#34;&gt;\(e^{iw}\)&lt;/span&gt;. The domain of Laplace transfomation is frequency &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; and damping component &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; which compose damping ocilation function, &lt;span class=&#34;math inline&#34;&gt;\(e^{s} = e^{(iw+\sigma)}\)&lt;/span&gt;. The function which represent Laplace transformation &lt;span class=&#34;math inline&#34;&gt;\(F(s)\)&lt;/span&gt; is a function of complex domain &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;. The Fourier transformation is a special Laplace transformation of no damping term &lt;span class=&#34;math inline&#34;&gt;\(s = 0 \cdot \sigma +iw\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;periodic&lt;/strong&gt; function can be represented by a series not a continuous function. A condition makes a function can be represented by pure frequency domain i.e. Fourier transformation, not a complex domain i.e. Laplace transformation. The condition is&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;from wikipedia &lt;a href=&#34;https://en.wikipedia.org/wiki/Laplace_transform#Fourier_transform&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Laplace_transform#Fourier_transform&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;math&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
  \widehat{f}(\omega) &amp;amp;= \mathcal{F}\{f(t)\} \\[4pt]
                  &amp;amp;= \mathcal{L}\{f(t)\}|_{s = i\omega}  =  F(s)|_{s = i \omega} \\[4pt]
                  &amp;amp;= \int_{-\infty}^\infty e^{-i \omega t} f(t)\,dt~.
\end{align}\]&lt;/span&gt;&lt;/math&gt;&lt;/p&gt;
&lt;p&gt;Laplace transformation makes a differential equation to an algebra equation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Laplace transformation\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mathcal{L}[f(t)] = F(s) = \int_{t=0}^{\infty} f(t)e^{-st}dt
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Transfer function\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H(s) = Y(s)/X(s)
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
Y(s) = H(s)X(s)  
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y(s)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X(s)\)&lt;/span&gt; are Laplace transformed &lt;span class=&#34;math inline&#34;&gt;\(y(t)\)&lt;/span&gt;, i.e. solution and &lt;span class=&#34;math inline&#34;&gt;\(f(t)\)&lt;/span&gt; i.e. input.&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(Y(s)\)&lt;/span&gt; is a function of &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; which represents coefficients of damped frquency basis &lt;span class=&#34;math inline&#34;&gt;\(e^{\sigma + iw}\)&lt;/span&gt;. We are not looking for the solution &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; for the &lt;span class=&#34;math inline&#34;&gt;\(Y(s)\)&lt;/span&gt;. We are looking for the inverse Laplace transformation of &lt;span class=&#34;math inline&#34;&gt;\(Y(s)\)&lt;/span&gt;. The inverse Laplace transformation turns a function &lt;span class=&#34;math inline&#34;&gt;\(Y(s)\)&lt;/span&gt; with infinite damped frquency basis &lt;span class=&#34;math inline&#34;&gt;\(e^{\sigma + iw}\)&lt;/span&gt; to the solution of linear differential equation &lt;span class=&#34;math inline&#34;&gt;\(y(t)\)&lt;/span&gt; that is a function with a single domain basis &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The Laplace transformation has poles that blow up at a point. The poles were determined by constants of differential equation and the input term.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convolution and Fourier transformation</title>
      <link>/post/convolution-and-fourier-transformation/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/post/convolution-and-fourier-transformation/</guid>
      <description>


&lt;p&gt;Convolution is a vector operation on two vectors.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Convolution \\ c * d = d*c \\ (c*d)_n = \Sigma_{i+j} c_i d_j = \Sigma_i c_i d_{n-i}.\]&lt;/span&gt;
This is multiplying polynomials. The parameters of multiplied polynomial become convolution of two polynomials. Fourier transformation expands x base to infinite exponential basis &lt;span class=&#34;math inline&#34;&gt;\(e^{iwk}\)&lt;/span&gt;. The &lt;strong&gt;multiplication on x (time) space&lt;/strong&gt; becomes &lt;strong&gt;convolutionn on k (frequency) space&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If time space is periodic, its Fourier transformation is discrete i.e. Fourier series. If time space is non-periodic, its Fourier transformation is continuous Fourier transformation.&lt;/p&gt;
&lt;p&gt;The Fourier transformation is dual. The relations of &lt;strong&gt;multiplication and convolution&lt;/strong&gt; and &lt;strong&gt;periodic and discrete&lt;/strong&gt; are dual in time space and frequency space.&lt;/p&gt;
&lt;p&gt;Fourier transformation is changing basis. The changing basis can be done by inner product (for vector space) or integration (function space) with new basis in which are we want move to space. This is why Fourier transformation coefficients calculated by integration with function multiplying basis &lt;span class=&#34;math inline&#34;&gt;\(e^{iwk}\)&lt;/span&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lagrange dual problem and conjugate function</title>
      <link>/post/lagrange-dual-problem-and-conjugate-function/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/post/lagrange-dual-problem-and-conjugate-function/</guid>
      <description>


&lt;p&gt;The optimization problem have two components that are objective function &lt;span class=&#34;math inline&#34;&gt;\(f_0 : \mathbb R ^n \rightarrow \mathbb R\)&lt;/span&gt; and the constraints. The objective function and constraints keep in check each other and make balance at saddle point i.e. optimal point. The dual (Lagrange) problem of the optimal problem also solve the optimization problem by making low boundary.&lt;/p&gt;
&lt;p&gt;The dual problem can be explained as a conjugate function &lt;span class=&#34;math inline&#34;&gt;\(f^* = \sup (x^Ty-f(x))\)&lt;/span&gt;. The Lagrangian is &lt;span class=&#34;math inline&#34;&gt;\(L(x, \lambda, \nu) = f_0(x) + \lambda f_1, + \nu f_2\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(f_0\)&lt;/span&gt; is the objective function, &lt;span class=&#34;math inline&#34;&gt;\(f_1\)&lt;/span&gt; is inequality constraints and &lt;span class=&#34;math inline&#34;&gt;\(f_2\)&lt;/span&gt; is equality constraints. The Lagrangian function is &lt;span class=&#34;math inline&#34;&gt;\(g(\lambda,nu) = \inf_{x}L(x, \lambda, \nu) = \inf_{x}(f_0(x) + \lambda f_{1} + \nu f_{2})\)&lt;/span&gt;. The second and third term of the Lagrangian function is can be rewriten as an inner product form &lt;span class=&#34;math inline&#34;&gt;\(x^{T}h(\lambda) + x^{T}i(\nu)\)&lt;/span&gt; and constant term with &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. Then the inner product term &lt;span class=&#34;math inline&#34;&gt;\(x^{T}h(\lambda) + x^{T}i(\nu)\)&lt;/span&gt; and objective term becomes a conjugate function.&lt;/p&gt;
&lt;p&gt;The conjugate function &lt;span class=&#34;math inline&#34;&gt;\(f^*(x)\)&lt;/span&gt; is similar in terms of balance and saddle point.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Approximation</title>
      <link>/post/approximation/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/post/approximation/</guid>
      <description>


&lt;p&gt;The purpose of approximation is finding optimal point &lt;span class=&#34;math inline&#34;&gt;\(x^*\)&lt;/span&gt; i.e. &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x^*) = 0\)&lt;/span&gt;. We need a step/search direction &lt;span class=&#34;math inline&#34;&gt;\(\Delta x\)&lt;/span&gt; and step size &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Taylor approximation has polynomial arguments that is a step and parameters of derivatives at the start point. The first degree of Taylor approximation has one adding term from start point &lt;span class=&#34;math inline&#34;&gt;\((x_0, F(x_0))\)&lt;/span&gt;. The adding term &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x) \Delta x\)&lt;/span&gt; is consistent with a parameter (gradient &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x)\)&lt;/span&gt;) and a argument (step &lt;span class=&#34;math inline&#34;&gt;\(\Delta x\)&lt;/span&gt;). The Taylor approximation does approximate &lt;span class=&#34;math inline&#34;&gt;\(F(x + \Delta x)\)&lt;/span&gt; for any search direction &lt;span class=&#34;math inline&#34;&gt;\(\Delta x\)&lt;/span&gt;. We want to choose &lt;span class=&#34;math inline&#34;&gt;\(\Delta x\)&lt;/span&gt; for the direction to the optimal point.&lt;/p&gt;
&lt;p&gt;The adding term of Taylor approximation &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x) \Delta x\)&lt;/span&gt; have level curve (level line). The smallest Euclidean norm of the level curve is achieved at the tangent. The gradient descent set the step to the gradient &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x)\)&lt;/span&gt;. This makes the adding term biggest with Euclidean norm &lt;span class=&#34;math inline&#34;&gt;\(\Vert \nabla F(x) \Vert^2\)&lt;/span&gt; i.e. dual norm &lt;span class=&#34;math inline&#34;&gt;\(\Vert \nabla F(x) \Vert_*\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Newton’s method is second degree of Taylor approximation &lt;span class=&#34;math inline&#34;&gt;\(F(x_0+\Delta x) \approx F(x_0) + \nabla F(x) \Delta x + 1/2\Delta x^T H \Delta x\)&lt;/span&gt;. We want to find &lt;span class=&#34;math inline&#34;&gt;\(\Delta x\)&lt;/span&gt; to minimize the second degree of Taylor approximation. In this case, the minimizing step is tangent of first adding term &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x) \Delta x\)&lt;/span&gt; and second adding term &lt;span class=&#34;math inline&#34;&gt;\(\Delta x^T H \Delta x\)&lt;/span&gt; i.e. Steepest descent in H norm &lt;span class=&#34;math inline&#34;&gt;\(\Vert \cdot \Vert _H\)&lt;/span&gt;. The newton’s method can be thought as approximation of gradient &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x)\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(\nabla F(x_0 + \Delta x) \approx \nabla F(x_0) + H \Delta x = 0,\ \Delta x = -H^{-1} \nabla F(x_0)\)&lt;/span&gt;. This is also the derivative of second degree of Taylor approximation with respect to &lt;span class=&#34;math inline&#34;&gt;\(\Delta x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But the Taylor approximation is local. In addition to a step, a step size is needed. A step size determines how far the step taken. Backtracking line search has two constant parameters 0 &amp;lt; &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; &amp;lt; 0.5, 0 &amp;lt; &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; &amp;lt; 1. The approximation is below the convex function. &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; tilts the slope i.e. gradient upside and the tilted approximation meets the convex function. &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the update rate of the step size until the the amount of the step is less than the point that tilted approximation meeets the convex function.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Steady state equilibrium</title>
      <link>/post/steady-state-equilibrium/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/steady-state-equilibrium/</guid>
      <description>


&lt;p&gt;The meaning of &lt;span class=&#34;math inline&#34;&gt;\(A^{T}\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Steady state equilibrium&lt;/li&gt;
&lt;li&gt;Graph Laplacian matrix &lt;span class=&#34;math inline&#34;&gt;\(A^{T}CA\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Differential equation and Laplacian matrix&lt;/li&gt;
&lt;li&gt;Derivative is a graph without branch.&lt;/li&gt;
&lt;li&gt;Row space and column space are dual.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(A^{T}\)&lt;/span&gt; are dual.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ref) Linear algebra and learning from data, Part IV, Gilbert Strang&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Differential equations and Fourier transformation</title>
      <link>/post/differential-equations-and-fourier-transformation/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/differential-equations-and-fourier-transformation/</guid>
      <description>


&lt;p&gt;Differential equations describe the change of state. The change relates to the state. The solutions of the differential equations are the status equations. The initial conditions set the time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; and status &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. The boundary conditions are the value of boundary &lt;span class=&#34;math inline&#34;&gt;\(y_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(dy \over dt\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(= ay + q(t)\)&lt;/span&gt; starting from &lt;span class=&#34;math inline&#34;&gt;\(y(0)\)&lt;/span&gt; at $t=0. inital conditions &lt;span class=&#34;math inline&#34;&gt;\(t = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y=1\)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(q(t)\)&lt;/span&gt; is a input and &lt;span class=&#34;math inline&#34;&gt;\(y(t)\)&lt;/span&gt; is a response. If &lt;span class=&#34;math inline&#34;&gt;\(q(t)\)&lt;/span&gt; is delta function, the response is said &lt;strong&gt;Impulse response&lt;/strong&gt; &lt;span class=&#34;math display&#34;&gt;\[y&amp;#39; -ay = \delta (t) \\ y(t)=e^{at}\]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The solutions are combination of particular solution and null solution &lt;span class=&#34;math inline&#34;&gt;\(y = y_t + y_n\)&lt;/span&gt;. The solution includes &lt;span class=&#34;math inline&#34;&gt;\(e^{at}\)&lt;/span&gt;. The differential equations can not be solved like polynomial equations, because the arguments of the differentia equation relate to each other by calculus in the background of the equation. They can not be treated as just different arguments. The &lt;strong&gt;Fourier transformation&lt;/strong&gt; puts the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and its derivative &lt;span class=&#34;math inline&#34;&gt;\(y&amp;#39;\)&lt;/span&gt; in the same functional space (Hilbert space). This transformation makes the differential equation problem to simple arithmetic problem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Fourier transformation &lt;span class=&#34;math inline&#34;&gt;\(F(x) = \Sigma ^{\infty}_{n=-\infty} c_{n}e^{inx}\)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The basis of the Fourier transformation is &lt;span class=&#34;math inline&#34;&gt;\(e^{inx}\)&lt;/span&gt;. If the coefficients of the basis &lt;span class=&#34;math inline&#34;&gt;\(c_{n}\)&lt;/span&gt; decay fater, &lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt; becomes smooth. If the coefficients are constant, &lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt; is delta function &lt;span class=&#34;math inline&#34;&gt;\(\delta(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The derivative &lt;span class=&#34;math inline&#34;&gt;\(dy \over dt\)&lt;/span&gt; is an linear transformation operator, i.e. inner product, because the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y&amp;#39;\)&lt;/span&gt; are in functional space with same basis. The defivative can be represented as a matix &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;. The derivative matrix is antisymetric i.e. &lt;span class=&#34;math inline&#34;&gt;\(A^T = -A\)&lt;/span&gt; and the minus second derivative matrix &lt;span class=&#34;math inline&#34;&gt;\(-d^{2}/dx^{2}\)&lt;/span&gt; is symetic positive definite. &lt;span class=&#34;math inline&#34;&gt;\(AAf = -A^{T}Af\)&lt;/span&gt;. The meaning of transverse of a matrix is &lt;span class=&#34;math inline&#34;&gt;\((Ax)^{T}y = x^{T}(A^{T}y)\)&lt;/span&gt;. &lt;strong&gt;Dual and inner product&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/secondDifferenceMat.png&#34; alt=&#34;Second differnce matrix K&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Second differnce matrix K&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The second difference matrix solves discrete differential equations. The N eigenvectors of K are &lt;span class=&#34;math inline&#34;&gt;\(y_{n} = (sin\ n\pi \Delta x, sin\ 2n\pi \Delta x,\ ..., sin\ Nn\pi \Delta x)\)&lt;/span&gt;. The N eigen values of K are the positive numbers &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{n} = 2-2cos {n \pi \over N+1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;How does exponent &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; mean in &lt;span class=&#34;math inline&#34;&gt;\(e^i\)&lt;/span&gt;? The exponent makes multiplication to addition. What does an imaginary exponent mean? The imaginary exponent tilts the value to a complex plane. If the base is natural base &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;, the value of &lt;span class=&#34;math inline&#34;&gt;\(e^i\)&lt;/span&gt; is in the unit circle of a complex plane. The cycle is &lt;span class=&#34;math inline&#34;&gt;\(2 \pi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The Fourier transformation for solving the difference equation provoked the subject of functional analysis 200 years ago.&lt;/p&gt;
&lt;p&gt;Reference&lt;br /&gt;
Differential Equations and Linear Algebra, Gilbert Strang&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Information</title>
      <link>/post/information/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/information/</guid>
      <description>


&lt;p&gt;Information relates to uncertainty. The Shannon information content of an outcome &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(h(x)=-log_{2}P(x)\)&lt;/span&gt;. The rare event has larger information than a common event. The unit of information is a bit (binary digit). Coding is a mapping from an outcome of an ensemble to binary digits &lt;span class=&#34;math inline&#34;&gt;\(\{0,1\}^+\)&lt;/span&gt;. A symbol code is a code for a &lt;strong&gt;single&lt;/strong&gt; ensemble. A block code is a code for a &lt;strong&gt;sequence&lt;/strong&gt; ensemble. A set of sequences of the ensemble has a typical subset. The cardinality of a typical set is &lt;span class=&#34;math inline&#34;&gt;\(2^{H_{2}X}\)&lt;/span&gt;. We can reduce a code length by mapping codes to only a typical set (the source coding theorem). The prefix code is an optimal symbol code. The Kraft inequality is the condition of prefix code &lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{i}2^{-l_{i}} \le 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The noisy-channel coding theorem describes the possible rate and block code length &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;. If the block code length &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is long enough, the channel looks like the noisy typewriter and arbitrary block error rate can be achieved with rate. The maximum rate is the capacity &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; of the channel. If the rate is small enough, the typical set of the output of the channel can be mapped for the typical set of input without overlap.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Entropy</title>
      <link>/post/entropy/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/entropy/</guid>
      <description>


&lt;p&gt;This is a note for Elements of information theory of Thomas M. Cover.&lt;/p&gt;
&lt;p&gt;The entropy (&lt;span class=&#34;math inline&#34;&gt;\(H\)&lt;/span&gt;) is a measure of uncertainty of a variable which is the answer to what is the ultimate data compression. Is the conditional probability &lt;span class=&#34;math inline&#34;&gt;\(p(x|y)\)&lt;/span&gt; considered as a probability of the “conditional variable” &lt;span class=&#34;math inline&#34;&gt;\((X|Y=y)\)&lt;/span&gt;? Yes, it is the subset of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; given &lt;span class=&#34;math inline&#34;&gt;\(Y=y\)&lt;/span&gt;. If you sum all of the subset probabilities, it becomes the cardinality of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Thus if you make that become 1, the conditional probability should be multiplied with &lt;span class=&#34;math inline&#34;&gt;\(p(x)\)&lt;/span&gt;. The conditional probability is larger than joint probabilities &lt;span class=&#34;math inline&#34;&gt;\(p(x,y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s think about the entropy of a joint random variable &lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; are correlated, the entries of the contingent table of &lt;span class=&#34;math inline&#34;&gt;\(p(x,y)\)&lt;/span&gt; are concentrated at some points that mean lager or smaller probabilities than a product of &lt;span class=&#34;math inline&#34;&gt;\(p(x)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(p(y)\)&lt;/span&gt;. The joint probability is a product of probability of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p(x)\)&lt;/span&gt; and conditional probability &lt;span class=&#34;math inline&#34;&gt;\(p(X|Y)\)&lt;/span&gt;. The conditional entropy is the expectation of a random conditional variable (conditional entropy). The conditional entropy does not mean the entropy of a subset of &lt;span class=&#34;math inline&#34;&gt;\(X|Y=y\)&lt;/span&gt;. It is a measure of uncertainty of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; given &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; has the &lt;strong&gt;information&lt;/strong&gt; of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, the entropy of &lt;span class=&#34;math inline&#34;&gt;\(X|Y\)&lt;/span&gt; is less than &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The conditional entropy &lt;span class=&#34;math inline&#34;&gt;\(H(X|Y)\)&lt;/span&gt; is subtract the entropy of Y &lt;span class=&#34;math inline&#34;&gt;\(H(Y)\)&lt;/span&gt; from joint entropy &lt;span class=&#34;math inline&#34;&gt;\(H(X,Y)\)&lt;/span&gt;. The joint probability &lt;span class=&#34;math inline&#34;&gt;\(p(x,y)\)&lt;/span&gt; is the product of probability of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and conditional probability &lt;span class=&#34;math inline&#34;&gt;\(p(x|Y=y)\)&lt;/span&gt;. This is chain rule of joint entropy &lt;span class=&#34;math inline&#34;&gt;\(H(X,Y) = H(Y) + H(X|Y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The chain rule is converting a joint variable to the sum of conditional random variables. The joint variable is the sum of conditional random variables. This is can be applied in the entropy, the information, and the relative entropy.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Duality</title>
      <link>/post/duality/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/duality/</guid>
      <description>


&lt;p&gt;This is summary of Boyd convex optimization. Steepest descent method is a convex optimization algorithm. The normalized steepest descent direction &lt;span class=&#34;math inline&#34;&gt;\(x_{nsd}\)&lt;/span&gt; is a vector of unit ball of a norm that extends in the direction &lt;span class=&#34;math inline&#34;&gt;\(-\nabla f(x)\)&lt;/span&gt;. The inner product of &lt;span class=&#34;math inline&#34;&gt;\(x_{nsd}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-\nabla f(x)\)&lt;/span&gt; is maximized. The first order Taylor approximation of &lt;span class=&#34;math inline&#34;&gt;\(f(x+v) = f(x) + \nabla f(x)^{T} v\)&lt;/span&gt; is most efficient when &lt;span class=&#34;math inline&#34;&gt;\(v = x_{nsd}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(x_{nsd}\)&lt;/span&gt; is unnormalized into &lt;span class=&#34;math inline&#34;&gt;\(x_{sd}\)&lt;/span&gt;. The normalization is ralated with unit ball of norm. When &lt;span class=&#34;math inline&#34;&gt;\(x_{nsd}\)&lt;/span&gt; is scaled with dual norm of &lt;span class=&#34;math inline&#34;&gt;\(-\nabla f(x)\)&lt;/span&gt;, the second term of Taylor approximation &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x)^{T} x_{sd}\)&lt;/span&gt; becomes convex (squre of &lt;strong&gt;dual norm&lt;/strong&gt; of gradient of &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;). The unnormalized &lt;span class=&#34;math inline&#34;&gt;\(x_{sd}\)&lt;/span&gt; the amount of movement of approximation because the inner product of gradient of &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; and unnormalized steepest descent direction is squre of &lt;strong&gt;dual norm&lt;/strong&gt; of gradient.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;dual norm&lt;/strong&gt; of gradient &lt;span class=&#34;math inline&#34;&gt;\(\lVert \nabla f(x) \rVert\)&lt;/span&gt; is main subject of this post. The simplest dual is a complement of a set. The &lt;span class=&#34;math inline&#34;&gt;\((C^c)^c\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; is small, &lt;span class=&#34;math inline&#34;&gt;\(C^C\)&lt;/span&gt; is large and vice versa. The dual cone is related to inner product and non-negativity. Let &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; be a cone, The set &lt;span class=&#34;math inline&#34;&gt;\(K^{*} = \{y|x^{T}y \geq 0\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(x \in K\}\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; is large, &lt;span class=&#34;math inline&#34;&gt;\(K^{*}\)&lt;/span&gt; is small and vice versa.&lt;/p&gt;
&lt;p&gt;The dual norm &lt;span class=&#34;math inline&#34;&gt;\(\left\lVert x \right\rVert _{*}\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\sup \{\, x^{T}y \mid \lVert y \rVert \leq 1 \,\}\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; direction is long axis of ellypsoid norm, the norm of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is small. But the dual norm is large because &lt;span class=&#34;math inline&#34;&gt;\(\lVert y \rVert _{2}\)&lt;/span&gt; large and vice versa.&lt;/p&gt;
&lt;p&gt;The main points are the first order Taylor approximation is most efficient with ellypsoid norm when the linear approximation is &lt;span class=&#34;math inline&#34;&gt;\(\sup\{\nabla f(x) ^{T} x_{sd}\}\)&lt;/span&gt; which is &lt;strong&gt;dual norm&lt;/strong&gt; of gradient of &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Strong convexity and implications</title>
      <link>/post/strong-convexity-and-implications/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/strong-convexity-and-implications/</guid>
      <description>


&lt;p&gt;This is a summary of the Boyd convex optimization book. The strong convexity assumption can be useful to explain the iterative minimization algorithms like gradient descent, steepest descent, and Newton’s method.&lt;/p&gt;
&lt;p&gt;The smallest and largest eigen value of Hessian &lt;span class=&#34;math inline&#34;&gt;\(m \preceq \nabla^{2}f(x) \preceq M\)&lt;/span&gt; with norm of gradient &lt;span class=&#34;math inline&#34;&gt;\(\| \nabla f(x)\|_2\)&lt;/span&gt; determine the boundary of optimal value &lt;span class=&#34;math inline&#34;&gt;\(p^{*}\)&lt;/span&gt;. The condition number of &lt;strong&gt;cond&lt;/strong&gt;(&lt;span class=&#34;math inline&#34;&gt;\(C_\alpha\)&lt;/span&gt;) &lt;span class=&#34;math inline&#34;&gt;\(\leq {M \over m}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(C_\alpha\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;-sublevel. The condition number is ratio of largest eigen value to its smallest eigen value.&lt;/p&gt;
&lt;p&gt;When the Hessian is replaced with a constant &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;, the constants make the equality of Taylor’s theorem to inequality that makes lower and upper boundaries of &lt;span class=&#34;math inline&#34;&gt;\(p^*\)&lt;/span&gt;. The difference between the approximation and &lt;span class=&#34;math inline&#34;&gt;\(p^*\)&lt;/span&gt; is determined by $ f(x)$ and &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x)\)&lt;/span&gt; is small and the gap is so. If Hessian (&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;) is large, the gap is small.&lt;/p&gt;
&lt;p&gt;Because the second degree of Tayler’s expansion is quadratic, at near the optimal point, the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;-sublevel is ellipsoid. The condition number &lt;strong&gt;cond&lt;/strong&gt;(&lt;span class=&#34;math inline&#34;&gt;\(C_{\alpha}\)&lt;/span&gt;), geometrically, represents anisometry or eccentricity&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convex set</title>
      <link>/post/convex-set/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/post/convex-set/</guid>
      <description>


&lt;p&gt;There is a homology between a line segment and a convex set. It is helpful to understand the convex set. A line, a line segment, and one sideline has homology to an affine set, a convex set, and a cone.
A line is &lt;span class=&#34;math inline&#34;&gt;\(\{y|y=\theta_1 x_1 + \theta_2 x_2, \theta_1 + \theta_2 = 1\}\)&lt;/span&gt; if &lt;span class=&#34;math inline&#34;&gt;\(\theta_1, \theta_2 \in \mathbb{R}\)&lt;/span&gt;, a line segment is if &lt;span class=&#34;math inline&#34;&gt;\(\theta_1, \theta_2 &amp;gt; 0\)&lt;/span&gt; and an one side line if any &lt;span class=&#34;math inline&#34;&gt;\(\theta_1, \theta_2 &amp;lt; 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A set &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; is affine set if $ y C$ and &lt;span class=&#34;math inline&#34;&gt;\(\{y|y=\theta_1 x_1 + \theta_2 x_2, \theta_1 + \theta_2 = 1, x_1, x_2 \in C, \theta_1, \theta_2 \in \mathbb{R} \}\)&lt;/span&gt;. a convex set is if &lt;span class=&#34;math inline&#34;&gt;\(\theta_1, \theta_2 &amp;gt; 0\)&lt;/span&gt; and a cone if any &lt;span class=&#34;math inline&#34;&gt;\(\theta_1, \theta_2 &amp;lt; 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;An affine set is a convex set. But all convex set is not an affine set. It looks the convex set has a stronger condition than affine set i.e. positivity of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. But in fact, the convex set has a stronger condition on what it should contain. Because an affine set contains more than a convex set, an affine set satisfies the condition to be a convex set.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducing Kernel Hilbert Space</title>
      <link>/post/reproducing-kernel-hilbert-space/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/post/reproducing-kernel-hilbert-space/</guid>
      <description>


&lt;p&gt;Finally arrive at reproducing kernel Hilbert space.
&lt;a href=&#34;https://nzer0.github.io/reproducing-kernel-hilbert-space.html&#34; class=&#34;uri&#34;&gt;https://nzer0.github.io/reproducing-kernel-hilbert-space.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The above post introduces RKHS in Korean. It was helpful. I had struggled to understand some concepts in RKHS. What does mean Hilbert space in terms of feature expansion? (&lt;span class=&#34;math inline&#34;&gt;\(f:\mathcal{X} \to \mathbb{R}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(f \in \mathcal{H}_K\)&lt;/span&gt;) It was confusing the difference between &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; means the function in Hilbert space and &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; is &lt;strong&gt;evaluation&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I thought that the function can be represented by the inner product of the basis of feature space &lt;span class=&#34;math inline&#34;&gt;\(K(\cdot,x)\)&lt;/span&gt; and coefficients &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;, and the coefficients are vectors in feature space.&lt;/p&gt;
&lt;p&gt;The reproducing property of Kernel is &lt;span class=&#34;math inline&#34;&gt;\(\langle f, K(\cdot,x)\rangle_{\mathcal{H}} = f(x)\)&lt;/span&gt;. Thus &lt;span class=&#34;math inline&#34;&gt;\(K(\cdot,x) \in \mathcal{H}_K\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(K(\cdot,x)\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; specified function in Hilbert space &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{H}_K\)&lt;/span&gt; and an evaluator of the specific point x. This means the inner product of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(K_{x}\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; at point &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In a nutshell, kenel method is a &lt;strong&gt;different way of evaluating f in a specific point &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/strong&gt;. &lt;strong&gt;Evaluating a function&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; at a point &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is inner product of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(L_x\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(L_x \in \mathcal{H}_K\)&lt;/span&gt; is a &lt;strong&gt;evaluation functional&lt;/strong&gt; which is a kernal function and linear &lt;span class=&#34;math inline&#34;&gt;\(K(\cdot, x)\)&lt;/span&gt;. Reproducing property of &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{H}_K\)&lt;/span&gt; can be achieved if all &lt;span class=&#34;math inline&#34;&gt;\(f \in \mathcal{H}\)&lt;/span&gt; has bounded evaluation functionals (&lt;span class=&#34;math inline&#34;&gt;\(L_x\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;In least square methods, the parameters (&lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt;) are determined by inner product of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta} = (X^{T}X)^{-1}X^{T}y\)&lt;/span&gt;. In Kernel method, &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; is determined &lt;span class=&#34;math inline&#34;&gt;\(\langle K(\cdot,x_i), K(\cdot,x_j), \rangle_{\mathcal{H}_K} = K(x_i, x_j)\)&lt;/span&gt;. Each &lt;span class=&#34;math inline&#34;&gt;\(K(\cdot, x)\)&lt;/span&gt; is a parameter and a argument (variable like &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Some subclass of the loss function and penalty functions can be generated by a positive definite kernel. A Kernel accepts two arguments and a Kernel function does one argument and the other argument becomes parameter. Reproducing Kernel Hilbert space is a function space with Kernal function space with the evaluation functional as a Kernel. The feature expansion into the RKHS can use the Kernel matrix instead of the inner product of each variable &lt;span class=&#34;math inline&#34;&gt;\(X^TX\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The important concepts are Hilbert space, inner product, Kernel function, evaluation functional, feature expansion, Fourier transformation, Reisz representation theorem (dual space &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{H}_{K}^*\)&lt;/span&gt; of Hibert space &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{H}_K\)&lt;/span&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Limit of inequality of sequence and epsilon</title>
      <link>/post/limit-of-inequality-and-epsilon/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/post/limit-of-inequality-and-epsilon/</guid>
      <description>


&lt;p&gt;Here I summarize some tools for proof of the Riesz representation theorem. They are the limit of inequality of sequence and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;. The Rudin’s proof of the Riesz representation theorem construct measure &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and measurable set &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}\)&lt;/span&gt;, then prove the &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}\)&lt;/span&gt; have properties. Countable additivity (not subadditivity) is an important property. The strategy of proving equality (additivity) is bidirectional inequality.&lt;/p&gt;
&lt;p&gt;Limit of inequality of sequence gives us a tool that finite inequality makes infinite inequality. &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; changes left and right parts of inequality (bidirectional inequality).&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(\Sigma^n_1\mu(K) \le \Sigma^n_1\mu(V_i)\)&lt;/span&gt; then &lt;span class=&#34;math inline&#34;&gt;\(\Sigma^{\infty}_1 \mu(K) \le \Sigma^{\infty}_1 \mu(V)\)&lt;/span&gt;, K is compact and V is open. We can change both sides of inequality with &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(\Sigma^{\infty}_1 \mu(V) \le \Sigma^{\infty}_1 \mu(K) + \epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Urison’s lemma is used for &lt;span class=&#34;math inline&#34;&gt;\(\mu(E) = \inf\mu(V) = \sup\mu(K)\)&lt;/span&gt; if $ E  $ and $ K E V$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Positive Borel measures</title>
      <link>/post/positive-borel-measures/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/post/positive-borel-measures/</guid>
      <description>


&lt;p&gt;This is a note of real and complex analysis chapter 2.&lt;/p&gt;
&lt;p&gt;Chapter 2 is about measures. The measure already defined in chapter 1. In chapter 2, every linear &lt;strong&gt;functionals&lt;/strong&gt;, not combination, of a continuous function space on compact set (&lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;) (&lt;span class=&#34;math inline&#34;&gt;\(\Lambda f\)&lt;/span&gt;) represents the integration of the function (&lt;span class=&#34;math inline&#34;&gt;\(\int f du\)&lt;/span&gt;) (Riesz representation theorem). Let X be a locally compact Hausdorf space, and let &lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt; be a positive linear functional on &lt;span class=&#34;math inline&#34;&gt;\(C_c(X)\)&lt;/span&gt;. Then there exist a &lt;span class=&#34;math inline&#34;&gt;\(\sigma-algebra\)&lt;/span&gt; in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; which contains all Borel sets in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, and there exists a unique positive measure &lt;span class=&#34;math inline&#34;&gt;\(mu\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}\)&lt;/span&gt; which represents &lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt; in the sense that (a) &lt;span class=&#34;math inline&#34;&gt;\(\Lambda f = \int f d \mu\)&lt;/span&gt; for every &lt;span class=&#34;math inline&#34;&gt;\(f \in C_c(X)\)&lt;/span&gt; and following additional properties:&lt;br /&gt;
(b) &lt;span class=&#34;math inline&#34;&gt;\(\mu(K) &amp;lt; \infty\)&lt;/span&gt; for every compact set &lt;span class=&#34;math inline&#34;&gt;\(K \subset X\)&lt;/span&gt;.&lt;br /&gt;
(c) For every &lt;span class=&#34;math inline&#34;&gt;\(E \in \mathfrak{M}\)&lt;/span&gt;, we have &lt;span class=&#34;math display&#34;&gt;\[ \mu(E) = inf\{\mu(V): E in V, V open\} \]&lt;/span&gt;.&lt;br /&gt;
(d) The relation &lt;span class=&#34;math display&#34;&gt;\[\mu(E)=sup\{\mu(K): K \in E, K compact\}\]&lt;/span&gt;&lt;br /&gt;
holds for every open set &lt;span class=&#34;math inline&#34;&gt;\(E\)&lt;/span&gt;, and for every &lt;span class=&#34;math inline&#34;&gt;\(E \in M\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(\mu(E) &amp;lt; \infty\)&lt;/span&gt;.&lt;br /&gt;
(e) If &lt;span class=&#34;math inline&#34;&gt;\(E \in \mathfrak{M}, A subset E\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\mu(E) = 0\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(A \in \mathfrak{M}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The Riesz theorem is about linear functional &lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt; is equivalently replaced with choosing measure &lt;span class=&#34;math inline&#34;&gt;\(\mu(E)=sup\{\Lambda f: f \prec V\}\)&lt;/span&gt;. Note &lt;span class=&#34;math inline&#34;&gt;\(sup \{\int^1_0 f(x)dx = \Lambda f: f \prec V, V (0,1) \} = 1\)&lt;/span&gt;. The notion of &lt;span class=&#34;math inline&#34;&gt;\(\prec\)&lt;/span&gt; include &lt;span class=&#34;math inline&#34;&gt;\(0 \le f \le 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;I confused &lt;span class=&#34;math inline&#34;&gt;\(C_c(X)\)&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Abstract integration</title>
      <link>/post/abstract-integration/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/post/abstract-integration/</guid>
      <description>


&lt;p&gt;This is a note for Rudin’s real and complex analysis chapter 1. The key concepts are &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;-algebra, measure (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) zero, and linear combination. The three concepts bring me abstract integration. The &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;-algebra makes that countable sum and measure of complement (subtract measure) can be possible. Measure zero completes the system. linear combination integrates a measurable function.&lt;/p&gt;
&lt;p&gt;After a measure space established, Lebesgue’s monotone convergence theorem, Fatou’s lemma, and Lebesgue’s dominant convergence theorem follow. Although three theorems do not contain &lt;strong&gt;integral&lt;/strong&gt; in their name, they insist that pointwise convergent sequence of functions is also converging their integral of the limit of functions. Lebesgue’s monotone convergence theorem requires a monotonous increment of series of functions and Lebesgue’s dominant convergence theorem requires upper bound function. Fatou’s lemma is the inequality of the lower limit.&lt;/p&gt;
&lt;p&gt;Lebesgue’s monotone convergence theorem can be proved by the fact all &lt;span class=&#34;math inline&#34;&gt;\(L_1(\mu)\)&lt;/span&gt; has convergent simple function sequence. &lt;span class=&#34;math inline&#34;&gt;\(f_n\)&lt;/span&gt; &amp;gt; simple functions holds inequality of &lt;span class=&#34;math inline&#34;&gt;\(\lim\int f_n \geq \lim\int S_n = \int f\)&lt;/span&gt;. Fatous’s lemma &lt;span class=&#34;math inline&#34;&gt;\(\lim \inf \int \lvert fn - f \rvert \leq\int \lim \inf \lvert f_n - f \rvert\)&lt;/span&gt; is used for proof of Lebesgue’s dominant convergence.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compactness</title>
      <link>/post/math/compactness/</link>
      <pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/post/math/compactness/</guid>
      <description>


&lt;p&gt;The compact is a property of space. In a nutshell, if space is compact, we can treat the space be a &lt;strong&gt;finite&lt;/strong&gt; because space has a &lt;strong&gt;finite subcover&lt;/strong&gt;. A continuous function on a compact space is uniformly continuous.&lt;/p&gt;
&lt;p&gt;Heine-Borel theorem describes the condition of compactness of &lt;strong&gt;finite&lt;/strong&gt; dimensional space. &lt;strong&gt;Closed and bounded&lt;/strong&gt; But the Heine-Borel theorem does not hold in an &lt;strong&gt;infinite-dimensional&lt;/strong&gt; space. We need another condition.&lt;/p&gt;
&lt;p&gt;Previously, the compact space can be finite by taking subcover. The infinite-dimensional space can be finite by projection to finite dimension. If we could make as small as possible (i.e. &lt;span class=&#34;math inline&#34;&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; ) the norm of &lt;span class=&#34;math inline&#34;&gt;\((X\backslash(1-P)\)&lt;/span&gt;, the compactness is achieved.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Limit</title>
      <link>/post/math/limit/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/math/limit/</guid>
      <description>


&lt;p&gt;A sequence can be defined as a function on the domain of natural number like &lt;span class=&#34;math inline&#34;&gt;\(1, 1/2, 1/3 ... 1/n\)&lt;/span&gt;. This sequence approach to the 0, but never touch the 0. However, people can not take their desire to link the sequence and the 0. Because &lt;span class=&#34;math inline&#34;&gt;\(\infty\)&lt;/span&gt; is not a member of the natural number even real number, another concept is necessary to link the sequence and the 0. It is the limit. &lt;span class=&#34;math display&#34;&gt;\[ \lim{n\to\infty} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above sequence approach to the 0. But does all sequences approach to some points? What if the sequence is &lt;span class=&#34;math inline&#34;&gt;\(1/n\)&lt;/span&gt; if &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is not multiple of 100, 0.001 if n is multiple of 100.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/math/2019-08-22-limit_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Its approach to zero except at every multiple of 10. The &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is used for the definition of limit to exclude this example.&lt;/p&gt;
&lt;p&gt;The sequence &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is converges the limit &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; if for every positive &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;, natural number &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is present such that &lt;span class=&#34;math inline&#34;&gt;\(\vert a-Sn \vert &amp;lt;\epsilon\)&lt;/span&gt; is true in every &lt;span class=&#34;math inline&#34;&gt;\(n&amp;gt;N\)&lt;/span&gt;. Otherwise, the limit is not defined and the sequence is divergent.&lt;/p&gt;
&lt;p&gt;In topological space, the &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; becomes the neighborhood.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Carathéodory&#39;s extension theorem</title>
      <link>/post/math/caratheodory-s-extension-theorem/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/math/caratheodory-s-extension-theorem/</guid>
      <description>


&lt;p&gt;The studying sometimes starts with learning of boring preceding concepts. The highlight comes later. In history, the highlight concepts or the important problem were centered and the supporting concepts or lemmas followed. One of the central ideas of analysis is &lt;strong&gt;extension&lt;/strong&gt;. The set of a rational number (&lt;span class=&#34;math inline&#34;&gt;\(\mathbb{Q}\)&lt;/span&gt;) extends to the real line &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{R}\)&lt;/span&gt;. The Jordan measurable sets extend to the Lebesgue measurable sets ( &lt;span class=&#34;math inline&#34;&gt;\(\sigma -algebra\)&lt;/span&gt; ).&lt;/p&gt;
&lt;p&gt;The outer measure can measure &lt;strong&gt;all&lt;/strong&gt; subsets of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, whereas measure can only measure a &lt;span class=&#34;math inline&#34;&gt;\(\sigma -algebra\)&lt;/span&gt; of measure set. The Carathéodory measurability defines the condition to make a &lt;span class=&#34;math inline&#34;&gt;\(\sigma -algebra\)&lt;/span&gt;.&lt;br /&gt;
&lt;span class=&#34;math display&#34;&gt;\[ \mu^*(A) = \mu^*(A \cap E) + \mu^*(A \cap E^c) \]&lt;/span&gt;
The Carathéodory extension theorem defines a condition to make an outer measure to a measure. The condition is that the outer measure applies to the Carathéodory measurable set (&lt;span class=&#34;math inline&#34;&gt;\(\sigma - algebra\)&lt;/span&gt;). (Torrence Tao, An introduction to measure theory)&lt;/p&gt;
&lt;p&gt;In the Riesz representation therorem, &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}_F\)&lt;/span&gt; extends to &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}\)&lt;/span&gt;. The outer measure is &lt;span class=&#34;math inline&#34;&gt;\(\mu(E) = sup\ \ \{\mu(K): K \subset E,\ \ K \ \ compact \}\)&lt;/span&gt; for every &lt;span class=&#34;math inline&#34;&gt;\(E \subset X\)&lt;/span&gt; analogus to Jordan outer measure. &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}_F\)&lt;/span&gt; is collection of subset &lt;span class=&#34;math inline&#34;&gt;\(E \subset X\)&lt;/span&gt; satisfying &lt;span class=&#34;math inline&#34;&gt;\(\mu (E) &amp;lt; \infty\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu (V) = sup \{\Lambda f:f\prec V \}\)&lt;/span&gt; analogus to Jordan inner measure. Thus &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}_F\)&lt;/span&gt; is analous to Jordan measurable set. &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}\)&lt;/span&gt; is collection of subset &lt;span class=&#34;math inline&#34;&gt;\(E \subset X\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(E \cap K \ \in \ \ \mathfrak{M}_F\)&lt;/span&gt; for every compact &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;. This is the Carathéodory measurability. So the &lt;span class=&#34;math inline&#34;&gt;\(\mu(E)\)&lt;/span&gt; on the &lt;span class=&#34;math inline&#34;&gt;\(\mathfrak{M}\)&lt;/span&gt; becomes measure. (Rudin’s Real and complex analysis)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
