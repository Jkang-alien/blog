<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tidymodel | Jun&#39;s Blog</title>
    <link>/categories/tidymodel/</link>
      <atom:link href="/categories/tidymodel/index.xml" rel="self" type="application/rss+xml" />
    <description>Tidymodel</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 26 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Tidymodel</title>
      <link>/categories/tidymodel/</link>
    </image>
    
    <item>
      <title>My first github issue</title>
      <link>/post/my-first-github-issue/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/my-first-github-issue/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;https://github.com/tidymodels/recipes/issues/482&#34; class=&#34;uri&#34;&gt;https://github.com/tidymodels/recipes/issues/482&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tidymodel and glmnet</title>
      <link>/post/tidymodel-and-glmnet/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/tidymodel-and-glmnet/</guid>
      <description>


&lt;p&gt;When the penalized generalize linear model (Lasso or Ridge) is processed in the tidymodel environment, finalizing the hyperparameter (lambda) and getting coefficients of the final model are confusing. Here is an example. This example predicts PIK3CA mutation status by gene expression data. TCGA breast cancer dataset is used.&lt;/p&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Modeling&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(glmnet)
library(themis)

set.seed(930093)
cv_splits &amp;lt;- rsample::vfold_cv(trainset_ahDiff, strata = PIK3CA_T)
mod &amp;lt;- logistic_reg(penalty = tune(),
                    mixture = tune()) %&amp;gt;%
  set_engine(&amp;quot;glmnet&amp;quot;)

rec &amp;lt;- recipe(PIK3CA_T ~ ., data = trainset_ahDiff) %&amp;gt;%
  step_BoxCox(all_numeric()) %&amp;gt;%
  step_dummy(HISTOLOGICAL_DIAGNOSIS) %&amp;gt;%
  step_center(all_numeric()) %&amp;gt;%
  step_scale(all_numeric()) %&amp;gt;%
  step_smote(PIK3CA_T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wfl &amp;lt;- workflow() %&amp;gt;%
  add_recipe(rec) %&amp;gt;%
  add_model(mod)

glmn_set &amp;lt;- parameters(penalty(range = c(-5,1), trans = log10_trans()),
                       mixture())

glmn_grid &amp;lt;- 
  grid_regular(glmn_set, levels = c(7, 5))
ctrl &amp;lt;- control_grid(save_pred = TRUE, verbose = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Grid parameter search on 10-fold cross-validation with 5 repeats&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Dummy variable to control for histologic subtype&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;select-best-parameter&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Select best parameter&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glmn_tune &amp;lt;- 
  tune_grid(wfl,
            resamples = cv_splits,
            grid = glmn_grid,
            metrics = metric_set(roc_auc),
            control = ctrl)


best_glmn &amp;lt;- select_best(glmn_tune, metric = &amp;quot;roc_auc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finalizing&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Finalizing&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wfl_final &amp;lt;- 
  wfl %&amp;gt;%
  finalize_workflow(best_glmn) %&amp;gt;%
  fit(data = trainset_ahDiff)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;finalize_workflow()&lt;/code&gt; finalizes the model with selected optimal hyperparameters. However, the glmnet fits any lambda, not the indicated lambda. This was discussed at &lt;a href=&#34;https://github.com/tidymodels/parsnip/issues/195&#34; class=&#34;uri&#34;&gt;https://github.com/tidymodels/parsnip/issues/195&lt;/a&gt;. The glmnet is more efficient to fit all lambda than a single lambda. Thus tidymodel ignores the indicated lambda. This made the first confusion. &lt;strong&gt;The finalization can be finalized by predict in tidymodel environment.&lt;/strong&gt; Finalize with &lt;code&gt;predict&lt;/code&gt;. Note the last argument &lt;code&gt;penalty = 1&lt;/code&gt; of &lt;code&gt;stats::predict(wfl_final, type = &#34;prob&#34;, new_data = trainset_ahDiff, penalty = 1)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_predict &amp;lt;- stats::predict(wfl_final, type = &amp;quot;prob&amp;quot;, new_data = trainset_ahDiff, penalty = 1)
train_probs &amp;lt;- 
  predict(wfl_final, type = &amp;quot;prob&amp;quot;, new_data = trainset_ahDiff) %&amp;gt;%
  bind_cols(obs = trainset_ahDiff$PIK3CA_T) %&amp;gt;%
  bind_cols(predict(wfl_final, new_data = trainset_ahDiff))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;performance&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Performance&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(train_probs, obs, .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Truth
## Prediction Wild Mutant
##     Wild    213     45
##     Mutant  123    158&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;autoplot(roc_curve(train_probs, obs, .pred_Mutant, event_level = &amp;quot;second&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-18-tidymodel-and-glmnet_files/figure-html/performance-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;roc_auc(train_probs, obs, .pred_Mutant, event_level = &amp;quot;second&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 roc_auc binary         0.770&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because glmnet fits the whole path, there are whole coefficients in the glmnet fit object &lt;code&gt;wfl_final&lt;/code&gt;. This was the second confusion. How to get the final model coefficients is below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;coefficients&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Coefficients&lt;/h5&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(extract_model(wfl_final)) %&amp;gt;%
  filter(lambda &amp;gt; 0.98 &amp;amp; lambda &amp;lt; 1.01)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 17 x 5
##    term                                           step estimate lambda dev.ratio
##    &amp;lt;chr&amp;gt;                                         &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 (Intercept)                                      55  -0.0630   1.00     0.123
##  2 C4A                                              55   0.0587   1.00     0.123
##  3 C5orf13                                          55   0.0587   1.00     0.123
##  4 CDSN                                             55   0.0706   1.00     0.123
##  5 CFB                                              55   0.0719   1.00     0.123
##  6 CYP21A2                                          55   0.0516   1.00     0.123
##  7 DGKE                                             55  -0.0709   1.00     0.123
##  8 FGD5                                             55   0.0670   1.00     0.123
##  9 GALNT10                                          55   0.0575   1.00     0.123
## 10 GOLM1                                            55   0.0689   1.00     0.123
## 11 GPX8                                             55   0.0657   1.00     0.123
## 12 KLK11                                            55   0.0145   1.00     0.123
## 13 NTN4                                             55   0.0578   1.00     0.123
## 14 SMYD3                                            55   0.0637   1.00     0.123
## 15 USP36                                            55  -0.0698   1.00     0.123
## 16 WBP2                                             55  -0.0652   1.00     0.123
## 17 HISTOLOGICAL_DIAGNOSIS_Infiltrating.Lobular.~    55  -0.0244   1.00     0.123&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidymodel</title>
      <link>/post/tidymodel/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/tidymodel/</guid>
      <description>


&lt;div id=&#34;machine-learning-and-tidymodel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Machine Learning and Tidymodel&lt;/h3&gt;
&lt;div id=&#34;model-setting-parsnip&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Model setting, {Parsnip}&lt;/h4&gt;
&lt;p&gt;Rpackage Parsnip standardizes model specification. Tidymodel follows the concept of lazy evaluation of the tidyverse. Parsnip sets unified specifications and lately evaluates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;feature-engineering-recipes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Feature engineering, {Recipes}&lt;/h4&gt;
&lt;p&gt;Recipes make preprocessing easy with &lt;code&gt;step_()&lt;/code&gt; functions. Recipes after specification calculate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;resampling-rsample&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Resampling, {rsample}&lt;/h4&gt;
&lt;p&gt;To choose a model and hyperparameters, we must validate the different models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;making-hyperparameter-set-dials&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Making hyperparameter set, {dials}&lt;/h4&gt;
&lt;p&gt;The Rpackage {dials} set hyperparameter similarily with {Parsnip}. {Dials} standadize parameter of each modeling algorithm.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;set-modeling-process-workflowr&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Set modeling process, {Workflowr}&lt;/h4&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-models-with-hyperparameter-tunes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Fit models with hyperparameter, {tunes}&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
